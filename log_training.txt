2024-05-11 05:00:06,068 - Log file for this run: /content/ai8x-training/logs/2024.05.11-050006/2024.05.11-050006.log
2024-05-11 05:00:10,042 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-05-11 05:00:10,043 - Optimizer Args: {'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-05-11 05:00:11,634 - This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.

2024-05-11 05:00:11,639 - Reading compression schedule from: policies/schedule-cifar-nas.yaml
2024-05-11 05:00:11,645 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2024-05-11 05:00:11,645 - 

2024-05-11 05:00:11,645 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:00:16,168 - Epoch: [0][  100/  500]    Overall Loss 1.853588    Objective Loss 1.853588                                        LR 0.010000    Time 0.045195    
2024-05-11 05:00:21,920 - Epoch: [0][  200/  500]    Overall Loss 1.715597    Objective Loss 1.715597                                        LR 0.010000    Time 0.051285    
2024-05-11 05:00:25,993 - Epoch: [0][  300/  500]    Overall Loss 1.615455    Objective Loss 1.615455                                        LR 0.010000    Time 0.047727    
2024-05-11 05:00:29,600 - Epoch: [0][  400/  500]    Overall Loss 1.536737    Objective Loss 1.536737                                        LR 0.010000    Time 0.044805    
2024-05-11 05:00:33,108 - Epoch: [0][  500/  500]    Overall Loss 1.466034    Objective Loss 1.466034    Top1 62.500000    Top5 96.000000    LR 0.010000    Time 0.042855    
2024-05-11 05:00:33,331 - --- validate (epoch=0)-----------
2024-05-11 05:00:33,332 - 10000 samples (100 per mini-batch)
2024-05-11 05:00:36,677 - Epoch: [0][  100/  100]    Loss 1.451096    Top1 52.450000    Top5 92.270000    
2024-05-11 05:00:36,869 - ==> Top1: 52.450    Top5: 92.270    Loss: 1.451

2024-05-11 05:00:36,871 - ==> Confusion:
[[848  34  19   0  12   0  10   8  57  12]
 [ 86 811   2   2   7   0   3   2  46  41]
 [303  11 245  19 264   2  89  36  17  14]
 [158  33  80 149 183  19 166  56  96  60]
 [109  12  55   7 621   4  47 126  13   6]
 [111  21 107 203 170  81  76 141  55  35]
 [ 42   7  31   6 197   0 681   2  25   9]
 [102  30  24  15 162   1  16 616   4  30]
 [309  36   4   0  10   0   4   3 619  15]
 [147 209   0   0  13   0   6  22  29 574]]

2024-05-11 05:00:36,875 - ==> Best [Top1: 52.450   Top5: 92.270   Sparsity:0.00   Params: 301760 on epoch: 0]
2024-05-11 05:00:36,875 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:00:36,905 - 

2024-05-11 05:00:36,905 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:00:41,071 - Epoch: [1][  100/  500]    Overall Loss 1.132428    Objective Loss 1.132428                                        LR 0.010000    Time 0.041627    
2024-05-11 05:00:44,752 - Epoch: [1][  200/  500]    Overall Loss 1.103906    Objective Loss 1.103906                                        LR 0.010000    Time 0.039204    
2024-05-11 05:00:49,162 - Epoch: [1][  300/  500]    Overall Loss 1.083717    Objective Loss 1.083717                                        LR 0.010000    Time 0.040810    
2024-05-11 05:00:54,904 - Epoch: [1][  400/  500]    Overall Loss 1.058616    Objective Loss 1.058616                                        LR 0.010000    Time 0.044954    
2024-05-11 05:00:58,486 - Epoch: [1][  500/  500]    Overall Loss 1.034772    Objective Loss 1.034772    Top1 67.000000    Top5 96.500000    LR 0.010000    Time 0.043122    
2024-05-11 05:00:58,643 - --- validate (epoch=1)-----------
2024-05-11 05:00:58,644 - 10000 samples (100 per mini-batch)
2024-05-11 05:01:00,808 - Epoch: [1][  100/  100]    Loss 1.178002    Top1 59.110000    Top5 96.350000    
2024-05-11 05:01:00,948 - ==> Top1: 59.110    Top5: 96.350    Loss: 1.178

2024-05-11 05:01:00,949 - ==> Confusion:
[[795  51  70  12   0   5   1  40  24   2]
 [ 26 925   6  11   1   8   0  19   3   1]
 [109   3 509  39  74  91  24 145   5   1]
 [ 56   8  69 340  21 327  15 158   5   1]
 [ 33   3  95  60 430  63  18 294   4   0]
 [ 20   2  49  75  12 685   0 156   0   1]
 [ 29  10  66 157  74 111 508  44   1   0]
 [ 14   6  28   4   8  72   0 867   0   1]
 [226 108  24  28   4  14   2  17 573   4]
 [ 83 479   6  25   1  11   0 102  14 279]]

2024-05-11 05:01:00,951 - ==> Best [Top1: 59.110   Top5: 96.350   Sparsity:0.00   Params: 301760 on epoch: 1]
2024-05-11 05:01:00,951 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:01:00,973 - 

2024-05-11 05:01:00,974 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:01:05,918 - Epoch: [2][  100/  500]    Overall Loss 0.903153    Objective Loss 0.903153                                        LR 0.010000    Time 0.049402    
2024-05-11 05:01:11,840 - Epoch: [2][  200/  500]    Overall Loss 0.882543    Objective Loss 0.882543                                        LR 0.010000    Time 0.054234    
2024-05-11 05:01:15,572 - Epoch: [2][  300/  500]    Overall Loss 0.871599    Objective Loss 0.871599                                        LR 0.010000    Time 0.048588    
2024-05-11 05:01:19,233 - Epoch: [2][  400/  500]    Overall Loss 0.863631    Objective Loss 0.863631                                        LR 0.010000    Time 0.045587    
2024-05-11 05:01:23,127 - Epoch: [2][  500/  500]    Overall Loss 0.848837    Objective Loss 0.848837    Top1 73.000000    Top5 98.500000    LR 0.010000    Time 0.044252    
2024-05-11 05:01:23,416 - --- validate (epoch=2)-----------
2024-05-11 05:01:23,417 - 10000 samples (100 per mini-batch)
2024-05-11 05:01:26,988 - Epoch: [2][  100/  100]    Loss 0.843076    Top1 71.100000    Top5 98.030000    
2024-05-11 05:01:27,242 - ==> Top1: 71.100    Top5: 98.030    Loss: 0.843

2024-05-11 05:01:27,243 - ==> Confusion:
[[674  17  60  58  24  24   7  19  96  21]
 [ 13 836   2  25   3  15   9   6  40  51]
 [ 62   0 511 107  72 161  46  27   9   5]
 [ 11   1  29 661  18 221  27  12  14   6]
 [ 10   3  60 153 557  89  46  76   5   1]
 [  5   1   8 203  13 742   9  17   2   0]
 [  4   0  40 138  26  49 735   2   6   0]
 [  4   2  10  56  25 177   2 714   4   6]
 [ 46  16  14  25  11  11   2   1 867   7]
 [ 22  51   4  31   2  26   3   9  39 813]]

2024-05-11 05:01:27,251 - ==> Best [Top1: 71.100   Top5: 98.030   Sparsity:0.00   Params: 301760 on epoch: 2]
2024-05-11 05:01:27,251 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:01:27,292 - 

2024-05-11 05:01:27,292 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:01:31,426 - Epoch: [3][  100/  500]    Overall Loss 0.766672    Objective Loss 0.766672                                        LR 0.010000    Time 0.041299    
2024-05-11 05:01:35,082 - Epoch: [3][  200/  500]    Overall Loss 0.763862    Objective Loss 0.763862                                        LR 0.010000    Time 0.038911    
2024-05-11 05:01:39,290 - Epoch: [3][  300/  500]    Overall Loss 0.754176    Objective Loss 0.754176                                        LR 0.010000    Time 0.039962    
2024-05-11 05:01:44,892 - Epoch: [3][  400/  500]    Overall Loss 0.753927    Objective Loss 0.753927                                        LR 0.010000    Time 0.043937    
2024-05-11 05:01:48,627 - Epoch: [3][  500/  500]    Overall Loss 0.746627    Objective Loss 0.746627    Top1 78.000000    Top5 97.000000    LR 0.010000    Time 0.042613    
2024-05-11 05:01:48,778 - --- validate (epoch=3)-----------
2024-05-11 05:01:48,779 - 10000 samples (100 per mini-batch)
2024-05-11 05:01:50,981 - Epoch: [3][  100/  100]    Loss 0.845064    Top1 70.910000    Top5 97.730000    
2024-05-11 05:01:51,119 - ==> Top1: 70.910    Top5: 97.730    Loss: 0.845

2024-05-11 05:01:51,119 - ==> Confusion:
[[671   8  99   9  77   0  38  33  55  10]
 [  9 813   2   7   9   0  54  22  37  47]
 [ 45   0 507  57 153  17 183  24   8   6]
 [  8   1  48 576  84  34 185  44   9  11]
 [  9   1  17  39 793   4  73  64   0   0]
 [  6   0  43 297  75 408  96  68   4   3]
 [  2   0  14  34  38   1 908   1   1   1]
 [  5   1  10  53  68  23  31 804   0   5]
 [ 43   2  13  12  28   0  59   6 825  12]
 [ 20  38   3  20  20   0  17  50  46 786]]

2024-05-11 05:01:51,122 - ==> Best [Top1: 71.100   Top5: 98.030   Sparsity:0.00   Params: 301760 on epoch: 2]
2024-05-11 05:01:51,122 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:01:51,140 - 

2024-05-11 05:01:51,140 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:01:55,926 - Epoch: [4][  100/  500]    Overall Loss 0.680670    Objective Loss 0.680670                                        LR 0.010000    Time 0.047820    
2024-05-11 05:02:01,816 - Epoch: [4][  200/  500]    Overall Loss 0.689851    Objective Loss 0.689851                                        LR 0.010000    Time 0.053337    
2024-05-11 05:02:05,542 - Epoch: [4][  300/  500]    Overall Loss 0.692239    Objective Loss 0.692239                                        LR 0.010000    Time 0.047970    
2024-05-11 05:02:09,256 - Epoch: [4][  400/  500]    Overall Loss 0.685211    Objective Loss 0.685211                                        LR 0.010000    Time 0.045257    
2024-05-11 05:02:13,304 - Epoch: [4][  500/  500]    Overall Loss 0.684234    Objective Loss 0.684234    Top1 76.500000    Top5 99.500000    LR 0.010000    Time 0.044295    
2024-05-11 05:02:13,576 - --- validate (epoch=4)-----------
2024-05-11 05:02:13,576 - 10000 samples (100 per mini-batch)
2024-05-11 05:02:17,406 - Epoch: [4][  100/  100]    Loss 0.695464    Top1 76.840000    Top5 98.290000    
2024-05-11 05:02:17,683 - ==> Top1: 76.840    Top5: 98.290    Loss: 0.695

2024-05-11 05:02:17,684 - ==> Confusion:
[[882  23   9   4   6   0   4   5  51  16]
 [ 14 931   0   0   0   0   2   0  15  38]
 [141  13 579  37  72  40  65  17  22  14]
 [ 47  23  58 493  52 141  68  33  33  52]
 [ 33  12  58  23 771  15  30  32  10  16]
 [ 16   9  48 101  36 680  24  42  20  24]
 [ 20   7  35  33  31   8 829   2  21  14]
 [ 45  11  37  16  51  38   4 761   9  28]
 [ 70  24   1   0   2   1   1   2 889  10]
 [ 27  73   2   1   0   1   1   0  26 869]]

2024-05-11 05:02:17,691 - ==> Best [Top1: 76.840   Top5: 98.290   Sparsity:0.00   Params: 301760 on epoch: 4]
2024-05-11 05:02:17,691 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:02:17,739 - 

2024-05-11 05:02:17,743 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:02:24,319 - Epoch: [5][  100/  500]    Overall Loss 0.654397    Objective Loss 0.654397                                        LR 0.010000    Time 0.065687    
2024-05-11 05:02:27,955 - Epoch: [5][  200/  500]    Overall Loss 0.647197    Objective Loss 0.647197                                        LR 0.010000    Time 0.051011    
2024-05-11 05:02:33,707 - Epoch: [5][  300/  500]    Overall Loss 0.642689    Objective Loss 0.642689                                        LR 0.010000    Time 0.053172    
2024-05-11 05:02:38,126 - Epoch: [5][  400/  500]    Overall Loss 0.639324    Objective Loss 0.639324                                        LR 0.010000    Time 0.050910    
2024-05-11 05:02:41,747 - Epoch: [5][  500/  500]    Overall Loss 0.636276    Objective Loss 0.636276    Top1 82.500000    Top5 98.500000    LR 0.010000    Time 0.047964    
2024-05-11 05:02:41,898 - --- validate (epoch=5)-----------
2024-05-11 05:02:41,898 - 10000 samples (100 per mini-batch)
2024-05-11 05:02:44,173 - Epoch: [5][  100/  100]    Loss 0.765961    Top1 74.270000    Top5 98.510000    
2024-05-11 05:02:44,313 - ==> Top1: 74.270    Top5: 98.510    Loss: 0.766

2024-05-11 05:02:44,313 - ==> Confusion:
[[767   4  78  22   8   1  14   8  95   3]
 [ 24 814   3   3   0   9  14   1 107  25]
 [ 31   0 768  44  40  23  68  11  14   1]
 [ 14   2  88 617  38  47 133  21  37   3]
 [ 12   0 123  42 697   5  83  26  12   0]
 [  8   0  84 254  36 510  63  30  14   1]
 [  4   0  54  26   7   2 904   1   2   0]
 [ 17   1  36  43  45  19  25 779  27   8]
 [ 47   3  10  10   1   2  10   0 916   1]
 [ 47  26   7  13   1   0  12   1 238 655]]

2024-05-11 05:02:44,316 - ==> Best [Top1: 76.840   Top5: 98.290   Sparsity:0.00   Params: 301760 on epoch: 4]
2024-05-11 05:02:44,316 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:02:44,333 - 

2024-05-11 05:02:44,334 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:02:50,497 - Epoch: [6][  100/  500]    Overall Loss 0.593269    Objective Loss 0.593269                                        LR 0.010000    Time 0.061529    
2024-05-11 05:02:55,259 - Epoch: [6][  200/  500]    Overall Loss 0.590599    Objective Loss 0.590599                                        LR 0.010000    Time 0.054544    
2024-05-11 05:02:58,853 - Epoch: [6][  300/  500]    Overall Loss 0.597988    Objective Loss 0.597988                                        LR 0.010000    Time 0.048335    
2024-05-11 05:03:02,418 - Epoch: [6][  400/  500]    Overall Loss 0.599784    Objective Loss 0.599784                                        LR 0.010000    Time 0.045157    
2024-05-11 05:03:07,335 - Epoch: [6][  500/  500]    Overall Loss 0.598347    Objective Loss 0.598347    Top1 79.500000    Top5 99.000000    LR 0.010000    Time 0.045929    
2024-05-11 05:03:07,601 - --- validate (epoch=6)-----------
2024-05-11 05:03:07,602 - 10000 samples (100 per mini-batch)
2024-05-11 05:03:09,838 - Epoch: [6][  100/  100]    Loss 0.824208    Top1 72.740000    Top5 98.340000    
2024-05-11 05:03:09,984 - ==> Top1: 72.740    Top5: 98.340    Loss: 0.824

2024-05-11 05:03:09,984 - ==> Confusion:
[[901   5  18  27   1   0   0  24  16   8]
 [ 34 922   0   6   0   6   1   6   6  19]
 [110   0 640 110  19  68   7  42   1   3]
 [ 42   4  43 717  10 137   5  37   2   3]
 [ 38   3  81 150 501  63  12 149   3   0]
 [ 13   1  32 177   5 735   1  36   0   0]
 [ 20   2 114 280  14  61 485  14  10   0]
 [ 21   4   9  46   4  39   0 874   1   2]
 [200  24   4  38   2   5   0   4 711  12]
 [ 80  69   4  26   0   2   0  21  10 788]]

2024-05-11 05:03:09,987 - ==> Best [Top1: 76.840   Top5: 98.290   Sparsity:0.00   Params: 301760 on epoch: 4]
2024-05-11 05:03:09,987 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:03:10,004 - 

2024-05-11 05:03:10,005 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:03:14,131 - Epoch: [7][  100/  500]    Overall Loss 0.590469    Objective Loss 0.590469                                        LR 0.010000    Time 0.041229    
2024-05-11 05:03:17,835 - Epoch: [7][  200/  500]    Overall Loss 0.585343    Objective Loss 0.585343                                        LR 0.010000    Time 0.039117    
2024-05-11 05:03:23,570 - Epoch: [7][  300/  500]    Overall Loss 0.576324    Objective Loss 0.576324                                        LR 0.010000    Time 0.045101    
2024-05-11 05:03:27,830 - Epoch: [7][  400/  500]    Overall Loss 0.573726    Objective Loss 0.573726                                        LR 0.010000    Time 0.044456    
2024-05-11 05:03:31,464 - Epoch: [7][  500/  500]    Overall Loss 0.567105    Objective Loss 0.567105    Top1 81.000000    Top5 99.500000    LR 0.010000    Time 0.042827    
2024-05-11 05:03:31,624 - --- validate (epoch=7)-----------
2024-05-11 05:03:31,624 - 10000 samples (100 per mini-batch)
2024-05-11 05:03:33,833 - Epoch: [7][  100/  100]    Loss 0.773653    Top1 75.390000    Top5 98.310000    
2024-05-11 05:03:33,972 - ==> Top1: 75.390    Top5: 98.310    Loss: 0.774

2024-05-11 05:03:33,973 - ==> Confusion:
[[916  22  40   1   4   1   0   5   9   2]
 [ 15 979   0   0   0   0   0   0   1   5]
 [ 75   9 704  32  71  31  35  26   3  14]
 [101  20  61 460  84 122  63  49  16  24]
 [ 50   8  68  13 729   8  20  94   4   6]
 [ 34   7  57  69  42 690  24  62  10   5]
 [ 23  21  63  26  47  12 789   5   6   8]
 [ 57   7  21  14  18  15   7 848   5   8]
 [195  53   3   1   0   2   1   1 736   8]
 [ 95 199   6   2   1   0   0   0   9 688]]

2024-05-11 05:03:33,976 - ==> Best [Top1: 76.840   Top5: 98.290   Sparsity:0.00   Params: 301760 on epoch: 4]
2024-05-11 05:03:33,976 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:03:33,994 - 

2024-05-11 05:03:33,994 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:03:39,698 - Epoch: [8][  100/  500]    Overall Loss 0.534755    Objective Loss 0.534755                                        LR 0.010000    Time 0.056998    
2024-05-11 05:03:44,276 - Epoch: [8][  200/  500]    Overall Loss 0.537358    Objective Loss 0.537358                                        LR 0.010000    Time 0.051348    
2024-05-11 05:03:47,986 - Epoch: [8][  300/  500]    Overall Loss 0.543358    Objective Loss 0.543358                                        LR 0.010000    Time 0.046581    
2024-05-11 05:03:51,589 - Epoch: [8][  400/  500]    Overall Loss 0.542974    Objective Loss 0.542974                                        LR 0.010000    Time 0.043935    
2024-05-11 05:03:57,032 - Epoch: [8][  500/  500]    Overall Loss 0.545743    Objective Loss 0.545743    Top1 83.000000    Top5 98.500000    LR 0.010000    Time 0.046028    
2024-05-11 05:03:57,260 - --- validate (epoch=8)-----------
2024-05-11 05:03:57,261 - 10000 samples (100 per mini-batch)
2024-05-11 05:03:59,520 - Epoch: [8][  100/  100]    Loss 0.613131    Top1 78.910000    Top5 98.930000    
2024-05-11 05:03:59,658 - ==> Top1: 78.910    Top5: 98.930    Loss: 0.613

2024-05-11 05:03:59,659 - ==> Confusion:
[[934   4  10   2  14   1   0  15  17   3]
 [ 45 901   0   5   1   1   1   7  10  29]
 [112   3 687  24  70  32  20  46   3   3]
 [ 51   1  62 541  83 108  27 115   6   6]
 [ 31   2  45  16 801  19  14  72   0   0]
 [ 12   1  55  90  36 698   7 100   0   1]
 [ 29   1  49  63  38  14 775  21   5   5]
 [ 19   1  10   5  25  17   1 921   0   1]
 [129   3   5   5   5   2   0  11 834   6]
 [106  44   3   3   3   1   0  18  23 799]]

2024-05-11 05:03:59,661 - ==> Best [Top1: 78.910   Top5: 98.930   Sparsity:0.00   Params: 301760 on epoch: 8]
2024-05-11 05:03:59,662 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:03:59,685 - 

2024-05-11 05:03:59,685 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:04:03,942 - Epoch: [9][  100/  500]    Overall Loss 0.509307    Objective Loss 0.509307                                        LR 0.010000    Time 0.042536    
2024-05-11 05:04:07,531 - Epoch: [9][  200/  500]    Overall Loss 0.514153    Objective Loss 0.514153                                        LR 0.010000    Time 0.039197    
2024-05-11 05:04:13,403 - Epoch: [9][  300/  500]    Overall Loss 0.520653    Objective Loss 0.520653                                        LR 0.010000    Time 0.045665    
2024-05-11 05:04:17,819 - Epoch: [9][  400/  500]    Overall Loss 0.521785    Objective Loss 0.521785                                        LR 0.010000    Time 0.045256    
2024-05-11 05:04:21,453 - Epoch: [9][  500/  500]    Overall Loss 0.521525    Objective Loss 0.521525    Top1 78.500000    Top5 99.000000    LR 0.010000    Time 0.043468    
2024-05-11 05:04:21,607 - --- validate (epoch=9)-----------
2024-05-11 05:04:21,607 - 10000 samples (100 per mini-batch)
2024-05-11 05:04:23,870 - Epoch: [9][  100/  100]    Loss 0.659386    Top1 78.060000    Top5 98.420000    
2024-05-11 05:04:24,007 - ==> Top1: 78.060    Top5: 98.420    Loss: 0.659

2024-05-11 05:04:24,008 - ==> Confusion:
[[859  15   6  14   4   0   4   2  89   7]
 [ 11 945   0   2   0   0   2   0  21  19]
 [ 99  10 630  85  51  13  58  10  32  12]
 [ 20  14  21 781  37  25  30  10  37  25]
 [ 35   9  39  75 766   4  28  17  23   4]
 [ 14   9  38 332  31 516  16  21  15   8]
 [ 10   5  17  80  19   3 850   0  11   5]
 [ 97  20  15  82  47  12   8 685  15  19]
 [ 32  10   1   6   0   0   2   1 942   6]
 [ 34  90   1   4   1   0   1   0  37 832]]

2024-05-11 05:04:24,010 - ==> Best [Top1: 78.910   Top5: 98.930   Sparsity:0.00   Params: 301760 on epoch: 8]
2024-05-11 05:04:24,011 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:04:24,028 - 

2024-05-11 05:04:24,029 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:04:29,663 - Epoch: [10][  100/  500]    Overall Loss 0.492843    Objective Loss 0.492843                                        LR 0.010000    Time 0.056305    
2024-05-11 05:04:34,741 - Epoch: [10][  200/  500]    Overall Loss 0.499997    Objective Loss 0.499997                                        LR 0.010000    Time 0.053351    
2024-05-11 05:04:38,327 - Epoch: [10][  300/  500]    Overall Loss 0.502832    Objective Loss 0.502832                                        LR 0.010000    Time 0.047512    
2024-05-11 05:04:42,015 - Epoch: [10][  400/  500]    Overall Loss 0.501005    Objective Loss 0.501005                                        LR 0.010000    Time 0.044846    
2024-05-11 05:04:46,807 - Epoch: [10][  500/  500]    Overall Loss 0.501190    Objective Loss 0.501190    Top1 83.000000    Top5 99.000000    LR 0.010000    Time 0.045453    
2024-05-11 05:04:47,033 - --- validate (epoch=10)-----------
2024-05-11 05:04:47,034 - 10000 samples (100 per mini-batch)
2024-05-11 05:04:49,833 - Epoch: [10][  100/  100]    Loss 0.627244    Top1 78.800000    Top5 98.990000    
2024-05-11 05:04:50,094 - ==> Top1: 78.800    Top5: 98.990    Loss: 0.627

2024-05-11 05:04:50,096 - ==> Confusion:
[[854  24  12   8  28   9  13  21  14  17]
 [  3 950   1   1   0   4  10   2   1  28]
 [ 63   1 549  19 130 133  71  29   2   3]
 [  9   4  22 412  78 366  71  29   2   7]
 [  6   1   6  10 896  42  19  18   1   1]
 [  3   0   6  27  36 899  14  15   0   0]
 [  6   0   8  16  47  46 873   4   0   0]
 [  6   1   4   9  69 100   4 806   0   1]
 [ 95  44   4   6  10   9  12   5 783  32]
 [ 15  89   2   9   6   6   3   5   7 858]]

2024-05-11 05:04:50,099 - ==> Best [Top1: 78.910   Top5: 98.930   Sparsity:0.00   Params: 301760 on epoch: 8]
2024-05-11 05:04:50,099 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:04:50,128 - 

2024-05-11 05:04:50,128 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:04:56,934 - Epoch: [11][  100/  500]    Overall Loss 0.483077    Objective Loss 0.483077                                        LR 0.010000    Time 0.067626    
2024-05-11 05:05:02,628 - Epoch: [11][  200/  500]    Overall Loss 0.484404    Objective Loss 0.484404                                        LR 0.010000    Time 0.062240    
2024-05-11 05:05:07,240 - Epoch: [11][  300/  500]    Overall Loss 0.476652    Objective Loss 0.476652                                        LR 0.010000    Time 0.056818    
2024-05-11 05:05:10,868 - Epoch: [11][  400/  500]    Overall Loss 0.482366    Objective Loss 0.482366                                        LR 0.010000    Time 0.051662    
2024-05-11 05:05:14,456 - Epoch: [11][  500/  500]    Overall Loss 0.484848    Objective Loss 0.484848    Top1 82.500000    Top5 99.500000    LR 0.010000    Time 0.048500    
2024-05-11 05:05:14,623 - --- validate (epoch=11)-----------
2024-05-11 05:05:14,624 - 10000 samples (100 per mini-batch)
2024-05-11 05:05:18,160 - Epoch: [11][  100/  100]    Loss 0.609412    Top1 78.900000    Top5 99.040000    
2024-05-11 05:05:18,443 - ==> Top1: 78.900    Top5: 99.040    Loss: 0.609

2024-05-11 05:05:18,445 - ==> Confusion:
[[842  34  25   5   2   4   8  13  45  22]
 [  5 968   1   0   0   1   7   2   3  13]
 [ 68   8 678  35  25  82  53  39   6   6]
 [ 28  14  41 437  21 329  56  48  12  14]
 [ 21   3  47  31 633 141  47  67   8   2]
 [  9   6  13  40   9 878  11  32   1   1]
 [  8   7  24  34   8  31 876   9   3   0]
 [  9   8   9   3   3  85   3 877   0   3]
 [ 31  59   3   2   0   6   7   7 857  28]
 [ 11 119   1   0   1   7   5   3   9 844]]

2024-05-11 05:05:18,453 - ==> Best [Top1: 78.910   Top5: 98.930   Sparsity:0.00   Params: 301760 on epoch: 8]
2024-05-11 05:05:18,454 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:05:18,487 - 

2024-05-11 05:05:18,487 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:05:22,775 - Epoch: [12][  100/  500]    Overall Loss 0.461719    Objective Loss 0.461719                                        LR 0.010000    Time 0.042791    
2024-05-11 05:05:26,364 - Epoch: [12][  200/  500]    Overall Loss 0.465215    Objective Loss 0.465215                                        LR 0.010000    Time 0.039318    
2024-05-11 05:05:30,565 - Epoch: [12][  300/  500]    Overall Loss 0.468442    Objective Loss 0.468442                                        LR 0.010000    Time 0.040190    
2024-05-11 05:05:36,542 - Epoch: [12][  400/  500]    Overall Loss 0.464439    Objective Loss 0.464439                                        LR 0.010000    Time 0.045062    
2024-05-11 05:05:40,137 - Epoch: [12][  500/  500]    Overall Loss 0.466823    Objective Loss 0.466823    Top1 80.500000    Top5 99.000000    LR 0.010000    Time 0.043235    
2024-05-11 05:05:40,288 - --- validate (epoch=12)-----------
2024-05-11 05:05:40,288 - 10000 samples (100 per mini-batch)
2024-05-11 05:05:42,496 - Epoch: [12][  100/  100]    Loss 0.569635    Top1 81.210000    Top5 99.000000    
2024-05-11 05:05:42,634 - ==> Top1: 81.210    Top5: 99.000    Loss: 0.570

2024-05-11 05:05:42,635 - ==> Confusion:
[[788  24  48  12  25   0  15   7  44  37]
 [  1 943   0   2   1   0   4   0   3  46]
 [ 29   5 720  10  98  19  80  21   2  16]
 [  5  15  72 486  96 115 125  49   8  29]
 [  3   3  22  12 883   6  42  24   5   0]
 [  2   8  56  72  80 704  30  40   3   5]
 [  1   1  14   9  30   5 935   4   1   0]
 [  6   9  23   7  72  14  11 844   2  12]
 [ 27  23   5   3   1   0  16   2 886  37]
 [  7  42   2   6   2   0   3   0   6 932]]

2024-05-11 05:05:42,638 - ==> Best [Top1: 81.210   Top5: 99.000   Sparsity:0.00   Params: 301760 on epoch: 12]
2024-05-11 05:05:42,638 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:05:42,833 - 

2024-05-11 05:05:42,833 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:05:47,272 - Epoch: [13][  100/  500]    Overall Loss 0.432081    Objective Loss 0.432081                                        LR 0.010000    Time 0.044262    
2024-05-11 05:05:53,231 - Epoch: [13][  200/  500]    Overall Loss 0.432944    Objective Loss 0.432944                                        LR 0.010000    Time 0.051788    
2024-05-11 05:05:57,179 - Epoch: [13][  300/  500]    Overall Loss 0.441921    Objective Loss 0.441921                                        LR 0.010000    Time 0.047662    
2024-05-11 05:06:00,827 - Epoch: [13][  400/  500]    Overall Loss 0.449239    Objective Loss 0.449239                                        LR 0.010000    Time 0.044860    
2024-05-11 05:06:04,449 - Epoch: [13][  500/  500]    Overall Loss 0.454408    Objective Loss 0.454408    Top1 82.500000    Top5 99.500000    LR 0.010000    Time 0.043128    
2024-05-11 05:06:04,684 - --- validate (epoch=13)-----------
2024-05-11 05:06:04,685 - 10000 samples (100 per mini-batch)
2024-05-11 05:06:08,062 - Epoch: [13][  100/  100]    Loss 0.663688    Top1 77.400000    Top5 98.860000    
2024-05-11 05:06:08,286 - ==> Top1: 77.400    Top5: 98.860    Loss: 0.664

2024-05-11 05:06:08,288 - ==> Confusion:
[[841  15   3  77   1   0  15   0  12  36]
 [  6 915   0   6   0   1  21   0   1  50]
 [ 71   1 659 132  50  26  55   2   1   3]
 [  7   1  27 885  19  28  26   3   0   4]
 [ 16   1  30 145 740  10  45  12   0   1]
 [  4   0  14 342  14 598  20   7   0   1]
 [  4   0  33 114   4   5 840   0   0   0]
 [ 18   3  12 191  38  66  20 649   0   3]
 [104  34   3  88   3   0  15   1 710  42]
 [  6  35   3  40   0   0  11   0   2 903]]

2024-05-11 05:06:08,292 - ==> Best [Top1: 81.210   Top5: 99.000   Sparsity:0.00   Params: 301760 on epoch: 12]
2024-05-11 05:06:08,293 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:06:08,322 - 

2024-05-11 05:06:08,323 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:06:12,630 - Epoch: [14][  100/  500]    Overall Loss 0.436345    Objective Loss 0.436345                                        LR 0.010000    Time 0.043036    
2024-05-11 05:06:16,301 - Epoch: [14][  200/  500]    Overall Loss 0.437594    Objective Loss 0.437594                                        LR 0.010000    Time 0.039859    
2024-05-11 05:06:20,635 - Epoch: [14][  300/  500]    Overall Loss 0.441035    Objective Loss 0.441035                                        LR 0.010000    Time 0.040979    
2024-05-11 05:06:26,423 - Epoch: [14][  400/  500]    Overall Loss 0.438327    Objective Loss 0.438327                                        LR 0.010000    Time 0.045193    
2024-05-11 05:06:30,019 - Epoch: [14][  500/  500]    Overall Loss 0.438632    Objective Loss 0.438632    Top1 84.500000    Top5 99.500000    LR 0.010000    Time 0.043339    
2024-05-11 05:06:30,175 - --- validate (epoch=14)-----------
2024-05-11 05:06:30,175 - 10000 samples (100 per mini-batch)
2024-05-11 05:06:32,412 - Epoch: [14][  100/  100]    Loss 0.636683    Top1 79.560000    Top5 98.880000    
2024-05-11 05:06:32,550 - ==> Top1: 79.560    Top5: 98.880    Loss: 0.637

2024-05-11 05:06:32,551 - ==> Confusion:
[[878  26  13   4   7   1   0  23  31  17]
 [  3 971   0   2   0   1   2   2   4  15]
 [ 75   9 576  41  54  47  40 138   6  14]
 [ 23  10  10 574  33 135  33 157   8  17]
 [ 11  10  22  31 718  22  17 159   5   5]
 [  5   3   6  86  22 696  10 167   1   4]
 [ 11   3  13  40  21  13 853  42   3   1]
 [  6   6   3   7   3   5   0 963   0   7]
 [ 37  45   0   4   1   1   4   9 876  23]
 [ 21 106   1   1   0   0   3   7  10 851]]

2024-05-11 05:06:32,553 - ==> Best [Top1: 81.210   Top5: 99.000   Sparsity:0.00   Params: 301760 on epoch: 12]
2024-05-11 05:06:32,554 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:06:32,570 - 

2024-05-11 05:06:32,571 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:06:36,925 - Epoch: [15][  100/  500]    Overall Loss 0.408078    Objective Loss 0.408078                                        LR 0.010000    Time 0.043506    
2024-05-11 05:06:42,845 - Epoch: [15][  200/  500]    Overall Loss 0.421769    Objective Loss 0.421769                                        LR 0.010000    Time 0.051315    
2024-05-11 05:06:46,640 - Epoch: [15][  300/  500]    Overall Loss 0.427850    Objective Loss 0.427850                                        LR 0.010000    Time 0.046828    
2024-05-11 05:06:50,272 - Epoch: [15][  400/  500]    Overall Loss 0.428909    Objective Loss 0.428909                                        LR 0.010000    Time 0.044195    
2024-05-11 05:06:54,196 - Epoch: [15][  500/  500]    Overall Loss 0.427870    Objective Loss 0.427870    Top1 87.500000    Top5 99.000000    LR 0.010000    Time 0.043199    
2024-05-11 05:06:54,452 - --- validate (epoch=15)-----------
2024-05-11 05:06:54,453 - 10000 samples (100 per mini-batch)
2024-05-11 05:06:57,875 - Epoch: [15][  100/  100]    Loss 0.560436    Top1 80.920000    Top5 99.160000    
2024-05-11 05:06:58,095 - ==> Top1: 80.920    Top5: 99.160    Loss: 0.560

2024-05-11 05:06:58,097 - ==> Confusion:
[[923   1   6  18   9  15   5  16   6   1]
 [ 21 931   1   4   1  14   4   2   8  14]
 [ 66   0 669  57  37  90  51  26   2   2]
 [ 14   0  19 637  22 252  36  19   0   1]
 [ 24   1  33  62 749  67  29  33   2   0]
 [  3   1   6  62  10 900   3  14   1   0]
 [  9   2  13  51  12  33 876   4   0   0]
 [ 12   2   3  24  14  77   3 864   0   1]
 [133  13   4  24   5  24   9   5 778   5]
 [ 97  79   0  16   0  22   4   8   9 765]]

2024-05-11 05:06:58,101 - ==> Best [Top1: 81.210   Top5: 99.000   Sparsity:0.00   Params: 301760 on epoch: 12]
2024-05-11 05:06:58,101 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:06:58,128 - 

2024-05-11 05:06:58,128 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:07:02,503 - Epoch: [16][  100/  500]    Overall Loss 0.414628    Objective Loss 0.414628                                        LR 0.010000    Time 0.043717    
2024-05-11 05:07:06,167 - Epoch: [16][  200/  500]    Overall Loss 0.415142    Objective Loss 0.415142                                        LR 0.010000    Time 0.040163    
2024-05-11 05:07:10,506 - Epoch: [16][  300/  500]    Overall Loss 0.413593    Objective Loss 0.413593                                        LR 0.010000    Time 0.041231    
2024-05-11 05:07:16,381 - Epoch: [16][  400/  500]    Overall Loss 0.415634    Objective Loss 0.415634                                        LR 0.010000    Time 0.045571    
2024-05-11 05:07:20,119 - Epoch: [16][  500/  500]    Overall Loss 0.416890    Objective Loss 0.416890    Top1 86.500000    Top5 100.000000    LR 0.010000    Time 0.043926    
2024-05-11 05:07:20,288 - --- validate (epoch=16)-----------
2024-05-11 05:07:20,289 - 10000 samples (100 per mini-batch)
2024-05-11 05:07:24,461 - Epoch: [16][  100/  100]    Loss 0.609670    Top1 80.300000    Top5 98.820000    
2024-05-11 05:07:24,686 - ==> Top1: 80.300    Top5: 98.820    Loss: 0.610

2024-05-11 05:07:24,687 - ==> Confusion:
[[916   1  34   3   9   0   0   9  18  10]
 [ 39 826   0   1   0   0   1   1   9 123]
 [ 42   1 843  15  53   6   3  23   3  11]
 [ 41   2 135 564  72  53  13  79  10  31]
 [ 17   1  60   6 841   3   6  59   2   5]
 [ 17   0 123  92  46 612   6  87   4  13]
 [ 20   1 150  27  57   7 696  24   4  14]
 [ 17   0  29   7  21   4   0 911   0  11]
 [ 74   4   9   3   2   0   0   6 882  20]
 [ 41   4   5   0   3   0   0   0   8 939]]

2024-05-11 05:07:24,690 - ==> Best [Top1: 81.210   Top5: 99.000   Sparsity:0.00   Params: 301760 on epoch: 12]
2024-05-11 05:07:24,691 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:07:24,715 - 

2024-05-11 05:07:24,715 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:07:31,828 - Epoch: [17][  100/  500]    Overall Loss 0.398056    Objective Loss 0.398056                                        LR 0.010000    Time 0.070982    
2024-05-11 05:07:37,327 - Epoch: [17][  200/  500]    Overall Loss 0.399226    Objective Loss 0.399226                                        LR 0.010000    Time 0.062928    
2024-05-11 05:07:41,020 - Epoch: [17][  300/  500]    Overall Loss 0.403302    Objective Loss 0.403302                                        LR 0.010000    Time 0.054253    
2024-05-11 05:07:44,624 - Epoch: [17][  400/  500]    Overall Loss 0.407270    Objective Loss 0.407270                                        LR 0.010000    Time 0.049685    
2024-05-11 05:07:49,153 - Epoch: [17][  500/  500]    Overall Loss 0.409916    Objective Loss 0.409916    Top1 85.500000    Top5 100.000000    LR 0.010000    Time 0.048800    
2024-05-11 05:07:49,384 - --- validate (epoch=17)-----------
2024-05-11 05:07:49,385 - 10000 samples (100 per mini-batch)
2024-05-11 05:07:51,865 - Epoch: [17][  100/  100]    Loss 0.621439    Top1 79.610000    Top5 98.820000    
2024-05-11 05:07:52,007 - ==> Top1: 79.610    Top5: 98.820    Loss: 0.621

2024-05-11 05:07:52,008 - ==> Confusion:
[[862  59  27   7   7   0   0   0  25  13]
 [  3 989   0   0   1   0   0   0   1   6]
 [ 55  11 810  43  35   7  27   2   3   7]
 [ 24  28  73 779  40  14  18   7   5  12]
 [ 11  10  49  49 836   1  26  11   4   3]
 [ 13  21  89 336  43 479   8   9   0   2]
 [  7  13  68  75  15   1 815   0   1   5]
 [ 29  21  44  61  79   1   3 747   2  13]
 [ 36  94   6   6   3   0   0   0 838  17]
 [  8 172   2   2   1   0   0   0   9 806]]

2024-05-11 05:07:52,011 - ==> Best [Top1: 81.210   Top5: 99.000   Sparsity:0.00   Params: 301760 on epoch: 12]
2024-05-11 05:07:52,011 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:07:52,028 - 

2024-05-11 05:07:52,028 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:07:56,291 - Epoch: [18][  100/  500]    Overall Loss 0.381725    Objective Loss 0.381725                                        LR 0.010000    Time 0.042587    
2024-05-11 05:07:59,913 - Epoch: [18][  200/  500]    Overall Loss 0.383569    Objective Loss 0.383569                                        LR 0.010000    Time 0.039392    
2024-05-11 05:08:05,533 - Epoch: [18][  300/  500]    Overall Loss 0.391117    Objective Loss 0.391117                                        LR 0.010000    Time 0.044983    
2024-05-11 05:08:09,679 - Epoch: [18][  400/  500]    Overall Loss 0.389643    Objective Loss 0.389643                                        LR 0.010000    Time 0.044070    
2024-05-11 05:08:13,459 - Epoch: [18][  500/  500]    Overall Loss 0.392197    Objective Loss 0.392197    Top1 88.500000    Top5 99.000000    LR 0.010000    Time 0.042810    
2024-05-11 05:08:13,609 - --- validate (epoch=18)-----------
2024-05-11 05:08:13,610 - 10000 samples (100 per mini-batch)
2024-05-11 05:08:16,132 - Epoch: [18][  100/  100]    Loss 0.552075    Top1 82.060000    Top5 99.110000    
2024-05-11 05:08:16,286 - ==> Top1: 82.060    Top5: 99.110    Loss: 0.552

2024-05-11 05:08:16,287 - ==> Confusion:
[[937   6   6  11   2   0   0   0  28  10]
 [ 21 898   0   2   0   0   3   0  13  63]
 [ 94   0 654  91  47  33  59   7   7   8]
 [ 31   1  11 818  24  59  34   4   9   9]
 [ 32   1  13  75 797  32  28  12   7   3]
 [ 17   0   7 253  15 689  10   3   3   3]
 [  9   0   9  61  12   3 903   0   3   0]
 [ 52   2  10  92  39  99   5 680   5  16]
 [ 49   6   0   8   0   1   2   0 908  26]
 [ 32  24   0   6   0   0   3   0  13 922]]

2024-05-11 05:08:16,289 - ==> Best [Top1: 82.060   Top5: 99.110   Sparsity:0.00   Params: 301760 on epoch: 18]
2024-05-11 05:08:16,289 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:08:16,312 - 

2024-05-11 05:08:16,313 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:08:22,599 - Epoch: [19][  100/  500]    Overall Loss 0.369030    Objective Loss 0.369030                                        LR 0.010000    Time 0.062817    
2024-05-11 05:08:26,999 - Epoch: [19][  200/  500]    Overall Loss 0.376529    Objective Loss 0.376529                                        LR 0.010000    Time 0.053347    
2024-05-11 05:08:30,648 - Epoch: [19][  300/  500]    Overall Loss 0.384791    Objective Loss 0.384791                                        LR 0.010000    Time 0.047697    
2024-05-11 05:08:34,381 - Epoch: [19][  400/  500]    Overall Loss 0.384566    Objective Loss 0.384566                                        LR 0.010000    Time 0.045098    
2024-05-11 05:08:39,901 - Epoch: [19][  500/  500]    Overall Loss 0.388373    Objective Loss 0.388373    Top1 89.000000    Top5 99.500000    LR 0.010000    Time 0.047060    
2024-05-11 05:08:40,148 - --- validate (epoch=19)-----------
2024-05-11 05:08:40,148 - 10000 samples (100 per mini-batch)
2024-05-11 05:08:42,439 - Epoch: [19][  100/  100]    Loss 0.540937    Top1 82.160000    Top5 99.150000    
2024-05-11 05:08:42,584 - ==> Top1: 82.160    Top5: 99.150    Loss: 0.541

2024-05-11 05:08:42,585 - ==> Confusion:
[[962   7   6   3   3   0   0   1   9   9]
 [ 19 950   0   0   0   0   0   0   5  26]
 [ 99   2 734  40  50  15  43   9   2   6]
 [ 65  10  35 695  39  49  74   9   9  15]
 [ 38   2  29  33 841  12  35   6   4   0]
 [ 37   9  31 164  33 670  41   7   2   6]
 [ 29   5  13  17  12   5 913   0   4   2]
 [ 76  12  24  36  76  22   9 728   6  11]
 [119  16   0   2   2   0   2   0 842  17]
 [ 60  46   0   2   0   0   1   0  10 881]]

2024-05-11 05:08:42,588 - ==> Best [Top1: 82.160   Top5: 99.150   Sparsity:0.00   Params: 301760 on epoch: 19]
2024-05-11 05:08:42,588 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:08:42,610 - 

2024-05-11 05:08:42,610 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:08:46,945 - Epoch: [20][  100/  500]    Overall Loss 0.374036    Objective Loss 0.374036                                        LR 0.010000    Time 0.043309    
2024-05-11 05:08:50,746 - Epoch: [20][  200/  500]    Overall Loss 0.376580    Objective Loss 0.376580                                        LR 0.010000    Time 0.040645    
2024-05-11 05:08:56,689 - Epoch: [20][  300/  500]    Overall Loss 0.376164    Objective Loss 0.376164                                        LR 0.010000    Time 0.046897    
2024-05-11 05:09:00,783 - Epoch: [20][  400/  500]    Overall Loss 0.375946    Objective Loss 0.375946                                        LR 0.010000    Time 0.045362    
2024-05-11 05:09:04,346 - Epoch: [20][  500/  500]    Overall Loss 0.377619    Objective Loss 0.377619    Top1 86.000000    Top5 99.500000    LR 0.010000    Time 0.043410    
2024-05-11 05:09:04,499 - --- validate (epoch=20)-----------
2024-05-11 05:09:04,499 - 10000 samples (100 per mini-batch)
2024-05-11 05:09:06,734 - Epoch: [20][  100/  100]    Loss 0.676875    Top1 78.750000    Top5 98.700000    
2024-05-11 05:09:06,871 - ==> Top1: 78.750    Top5: 98.700    Loss: 0.677

2024-05-11 05:09:06,872 - ==> Confusion:
[[964  13   2   2   1   0   0   2   6  10]
 [  8 976   0   1   0   1   0   0   1  13]
 [170   7 623  38  18  90  34  15   0   5]
 [ 66  20  18 561  17 257  29  16   3  13]
 [ 52   6  26  60 686 100  29  36   3   2]
 [ 22  10   7  40  10 896   3  10   1   1]
 [ 26  13  19  41   6  65 819   4   3   4]
 [ 55  24   7  17   9 111   1 767   1   8]
 [190  48   1   3   1   4   0   2 739  12]
 [ 36 108   0   2   1   3   1   0   5 844]]

2024-05-11 05:09:06,874 - ==> Best [Top1: 82.160   Top5: 99.150   Sparsity:0.00   Params: 301760 on epoch: 19]
2024-05-11 05:09:06,874 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:09:06,892 - 

2024-05-11 05:09:06,892 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:09:12,714 - Epoch: [21][  100/  500]    Overall Loss 0.361107    Objective Loss 0.361107                                        LR 0.010000    Time 0.058187    
2024-05-11 05:09:17,596 - Epoch: [21][  200/  500]    Overall Loss 0.372067    Objective Loss 0.372067                                        LR 0.010000    Time 0.053413    
2024-05-11 05:09:21,278 - Epoch: [21][  300/  500]    Overall Loss 0.368642    Objective Loss 0.368642                                        LR 0.010000    Time 0.047874    
2024-05-11 05:09:25,050 - Epoch: [21][  400/  500]    Overall Loss 0.367897    Objective Loss 0.367897                                        LR 0.010000    Time 0.045327    
2024-05-11 05:09:30,438 - Epoch: [21][  500/  500]    Overall Loss 0.370765    Objective Loss 0.370765    Top1 86.500000    Top5 99.500000    LR 0.010000    Time 0.046996    
2024-05-11 05:09:30,676 - --- validate (epoch=21)-----------
2024-05-11 05:09:30,676 - 10000 samples (100 per mini-batch)
2024-05-11 05:09:32,936 - Epoch: [21][  100/  100]    Loss 0.459949    Top1 84.860000    Top5 99.350000    
2024-05-11 05:09:33,075 - ==> Top1: 84.860    Top5: 99.350    Loss: 0.460

2024-05-11 05:09:33,076 - ==> Confusion:
[[845  18  28  15  12   0   5   2  54  21]
 [  4 951   2   1   1   1   2   0   7  31]
 [ 39   0 817  27  36  17  51   6   2   5]
 [  6   7  66 710  38  82  71   8   6   6]
 [  4   1  29  32 849  16  52  13   3   1]
 [  6   1  40 131  27 763  21   5   3   3]
 [  3   1  23  16   7   3 943   0   3   1]
 [ 14   9  31  37  53  58  22 769   1   6]
 [ 19  16   4  10   2   1   6   0 927  15]
 [  7  56   2   4   1   0   7   0  11 912]]

2024-05-11 05:09:33,078 - ==> Best [Top1: 84.860   Top5: 99.350   Sparsity:0.00   Params: 301760 on epoch: 21]
2024-05-11 05:09:33,078 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:09:33,100 - 

2024-05-11 05:09:33,101 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:09:37,141 - Epoch: [22][  100/  500]    Overall Loss 0.355497    Objective Loss 0.355497                                        LR 0.010000    Time 0.040369    
2024-05-11 05:09:40,791 - Epoch: [22][  200/  500]    Overall Loss 0.358099    Objective Loss 0.358099                                        LR 0.010000    Time 0.038417    
2024-05-11 05:09:46,528 - Epoch: [22][  300/  500]    Overall Loss 0.362648    Objective Loss 0.362648                                        LR 0.010000    Time 0.044672    
2024-05-11 05:09:50,886 - Epoch: [22][  400/  500]    Overall Loss 0.362397    Objective Loss 0.362397                                        LR 0.010000    Time 0.044377    
2024-05-11 05:09:54,432 - Epoch: [22][  500/  500]    Overall Loss 0.361686    Objective Loss 0.361686    Top1 88.500000    Top5 99.000000    LR 0.010000    Time 0.042587    
2024-05-11 05:09:54,599 - --- validate (epoch=22)-----------
2024-05-11 05:09:54,600 - 10000 samples (100 per mini-batch)
2024-05-11 05:09:56,827 - Epoch: [22][  100/  100]    Loss 0.532477    Top1 82.050000    Top5 99.380000    
2024-05-11 05:09:56,965 - ==> Top1: 82.050    Top5: 99.380    Loss: 0.532

2024-05-11 05:09:56,965 - ==> Confusion:
[[818  24  14  36   3   3   2   2  79  19]
 [  3 964   0   3   1   3   1   1   8  16]
 [ 52   3 746  96  37  21  21  13   6   5]
 [ 12   3  26 855  23  54  11   4   8   4]
 [ 15   2  25 105 765  42  18  17  11   0]
 [  6   0  17 252  13 702   1   7   0   2]
 [  6   3  34 118  15  16 805   1   1   1]
 [ 11   6  12  97  19  78   2 769   1   5]
 [ 15  18   3  12   1   2   2   1 942   4]
 [  7 116   2  16   0   0   0   1  19 839]]

2024-05-11 05:09:56,968 - ==> Best [Top1: 84.860   Top5: 99.350   Sparsity:0.00   Params: 301760 on epoch: 21]
2024-05-11 05:09:56,968 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:09:56,987 - 

2024-05-11 05:09:56,988 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:10:03,204 - Epoch: [23][  100/  500]    Overall Loss 0.341459    Objective Loss 0.341459                                        LR 0.010000    Time 0.062125    
2024-05-11 05:10:09,675 - Epoch: [23][  200/  500]    Overall Loss 0.345305    Objective Loss 0.345305                                        LR 0.010000    Time 0.063381    
2024-05-11 05:10:13,672 - Epoch: [23][  300/  500]    Overall Loss 0.349463    Objective Loss 0.349463                                        LR 0.010000    Time 0.055553    
2024-05-11 05:10:17,315 - Epoch: [23][  400/  500]    Overall Loss 0.350603    Objective Loss 0.350603                                        LR 0.010000    Time 0.050765    
2024-05-11 05:10:21,805 - Epoch: [23][  500/  500]    Overall Loss 0.356452    Objective Loss 0.356452    Top1 86.500000    Top5 99.000000    LR 0.010000    Time 0.049586    
2024-05-11 05:10:22,090 - --- validate (epoch=23)-----------
2024-05-11 05:10:22,093 - 10000 samples (100 per mini-batch)
2024-05-11 05:10:24,487 - Epoch: [23][  100/  100]    Loss 0.553277    Top1 82.380000    Top5 99.100000    
2024-05-11 05:10:24,645 - ==> Top1: 82.380    Top5: 99.100    Loss: 0.553

2024-05-11 05:10:24,645 - ==> Confusion:
[[873   2  52  24  11   0   2   2  30   4]
 [ 29 858  11  16   1   6   4   2  39  34]
 [ 31   0 871  38  35  16   6   1   2   0]
 [  9   0  76 776  24  96  10   5   3   1]
 [  8   0  58  40 851  32   6   4   1   0]
 [  4   0  47 147  21 772   3   6   0   0]
 [  5   0  99  72  26  25 772   0   1   0]
 [ 10   0  61  49  87  80   0 711   1   1]
 [ 40   0   8  23   5   3   3   0 917   1]
 [ 48  17  21  31   8   6   4   5  23 837]]

2024-05-11 05:10:24,648 - ==> Best [Top1: 84.860   Top5: 99.350   Sparsity:0.00   Params: 301760 on epoch: 21]
2024-05-11 05:10:24,648 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:10:24,668 - 

2024-05-11 05:10:24,669 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:10:28,813 - Epoch: [24][  100/  500]    Overall Loss 0.337253    Objective Loss 0.337253                                        LR 0.010000    Time 0.041403    
2024-05-11 05:10:32,544 - Epoch: [24][  200/  500]    Overall Loss 0.344438    Objective Loss 0.344438                                        LR 0.010000    Time 0.039333    
2024-05-11 05:10:38,209 - Epoch: [24][  300/  500]    Overall Loss 0.344088    Objective Loss 0.344088                                        LR 0.010000    Time 0.045096    
2024-05-11 05:10:42,100 - Epoch: [24][  400/  500]    Overall Loss 0.343667    Objective Loss 0.343667                                        LR 0.010000    Time 0.043537    
2024-05-11 05:10:45,641 - Epoch: [24][  500/  500]    Overall Loss 0.345358    Objective Loss 0.345358    Top1 85.500000    Top5 99.500000    LR 0.010000    Time 0.041905    
2024-05-11 05:10:45,799 - --- validate (epoch=24)-----------
2024-05-11 05:10:45,800 - 10000 samples (100 per mini-batch)
2024-05-11 05:10:48,206 - Epoch: [24][  100/  100]    Loss 0.467785    Top1 84.510000    Top5 99.350000    
2024-05-11 05:10:48,363 - ==> Top1: 84.510    Top5: 99.350    Loss: 0.468

2024-05-11 05:10:48,363 - ==> Confusion:
[[789  25  39  30  19   4   3   3  54  34]
 [  2 935   2   2   3   1   4   0  10  41]
 [ 24   2 752  42  70  38  56  10   3   3]
 [  6   2  36 699  82  87  59   8   8  13]
 [  2   1  22  20 917  10  16   8   4   0]
 [  1   0  11 115  61 776  23  11   2   0]
 [  3   1  14  18  27   4 930   1   1   1]
 [  4   2  13  53  89  33   8 791   2   5]
 [ 23   9   5   5   1   0   7   1 936  13]
 [  3  41   4   7   2   0   4   0  13 926]]

2024-05-11 05:10:48,366 - ==> Best [Top1: 84.860   Top5: 99.350   Sparsity:0.00   Params: 301760 on epoch: 21]
2024-05-11 05:10:48,366 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:10:48,393 - 

2024-05-11 05:10:48,393 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:10:54,502 - Epoch: [25][  100/  500]    Overall Loss 0.326198    Objective Loss 0.326198                                        LR 0.010000    Time 0.061043    
2024-05-11 05:10:59,054 - Epoch: [25][  200/  500]    Overall Loss 0.334243    Objective Loss 0.334243                                        LR 0.010000    Time 0.053219    
2024-05-11 05:11:02,614 - Epoch: [25][  300/  500]    Overall Loss 0.337067    Objective Loss 0.337067                                        LR 0.010000    Time 0.047337    
2024-05-11 05:11:06,239 - Epoch: [25][  400/  500]    Overall Loss 0.340565    Objective Loss 0.340565                                        LR 0.010000    Time 0.044554    
2024-05-11 05:11:11,350 - Epoch: [25][  500/  500]    Overall Loss 0.341741    Objective Loss 0.341741    Top1 88.000000    Top5 100.000000    LR 0.010000    Time 0.045860    
2024-05-11 05:11:11,573 - --- validate (epoch=25)-----------
2024-05-11 05:11:11,573 - 10000 samples (100 per mini-batch)
2024-05-11 05:11:13,773 - Epoch: [25][  100/  100]    Loss 0.418512    Top1 86.190000    Top5 99.430000    
2024-05-11 05:11:13,923 - ==> Top1: 86.190    Top5: 99.430    Loss: 0.419

2024-05-11 05:11:13,923 - ==> Confusion:
[[887  18  30  10  15   4   2   2  18  14]
 [  4 957   2   2   1   1   1   0   6  26]
 [ 29   0 833  31  37  27  29  10   1   3]
 [ 13   2  68 711  40 128  18   9   3   8]
 [  7   0  42  32 846  23  20  26   4   0]
 [  4   0  26  82  26 834   9  16   1   2]
 [  4   1  50  55  12  13 863   2   0   0]
 [  8   3  26  18  18  36   1 887   0   3]
 [ 56  15   9   8   0   4   3   2 891  12]
 [ 13  53   3   6   1   1   3   3   7 910]]

2024-05-11 05:11:13,926 - ==> Best [Top1: 86.190   Top5: 99.430   Sparsity:0.00   Params: 301760 on epoch: 25]
2024-05-11 05:11:13,926 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:11:13,948 - 

2024-05-11 05:11:13,949 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:11:18,043 - Epoch: [26][  100/  500]    Overall Loss 0.321697    Objective Loss 0.321697                                        LR 0.010000    Time 0.040905    
2024-05-11 05:11:21,787 - Epoch: [26][  200/  500]    Overall Loss 0.325686    Objective Loss 0.325686                                        LR 0.010000    Time 0.039155    
2024-05-11 05:11:27,525 - Epoch: [26][  300/  500]    Overall Loss 0.328454    Objective Loss 0.328454                                        LR 0.010000    Time 0.045188    
2024-05-11 05:11:31,850 - Epoch: [26][  400/  500]    Overall Loss 0.332587    Objective Loss 0.332587                                        LR 0.010000    Time 0.044665    
2024-05-11 05:11:35,346 - Epoch: [26][  500/  500]    Overall Loss 0.333737    Objective Loss 0.333737    Top1 89.500000    Top5 99.500000    LR 0.010000    Time 0.042720    
2024-05-11 05:11:35,496 - --- validate (epoch=26)-----------
2024-05-11 05:11:35,496 - 10000 samples (100 per mini-batch)
2024-05-11 05:11:37,665 - Epoch: [26][  100/  100]    Loss 0.587464    Top1 82.270000    Top5 99.150000    
2024-05-11 05:11:37,805 - ==> Top1: 82.270    Top5: 99.150    Loss: 0.587

2024-05-11 05:11:37,806 - ==> Confusion:
[[900   5  11   7  17   0  10   3  46   1]
 [ 14 933   0   0   4   1  16   4  21   7]
 [ 62   1 700  13  63  36  97  24   3   1]
 [ 24   0  30 498  80 156 162  35  14   1]
 [  6   0  14   2 877  11  67  20   3   0]
 [ 11   1  12  44  53 792  50  32   5   0]
 [  5   1  10   5  12   4 959   3   1   0]
 [ 14   2   6   6  47  18   3 901   2   1]
 [ 35   7   2   3   4   0  12   1 936   0]
 [ 67 107   0   0   3   0  22   9  61 731]]

2024-05-11 05:11:37,808 - ==> Best [Top1: 86.190   Top5: 99.430   Sparsity:0.00   Params: 301760 on epoch: 25]
2024-05-11 05:11:37,809 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:11:37,829 - 

2024-05-11 05:11:37,829 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:11:43,653 - Epoch: [27][  100/  500]    Overall Loss 0.320694    Objective Loss 0.320694                                        LR 0.010000    Time 0.058083    
2024-05-11 05:11:48,535 - Epoch: [27][  200/  500]    Overall Loss 0.324782    Objective Loss 0.324782                                        LR 0.010000    Time 0.053392    
2024-05-11 05:11:52,193 - Epoch: [27][  300/  500]    Overall Loss 0.323255    Objective Loss 0.323255                                        LR 0.010000    Time 0.047778    
2024-05-11 05:11:55,795 - Epoch: [27][  400/  500]    Overall Loss 0.325488    Objective Loss 0.325488                                        LR 0.010000    Time 0.044833    
2024-05-11 05:12:00,632 - Epoch: [27][  500/  500]    Overall Loss 0.328685    Objective Loss 0.328685    Top1 91.500000    Top5 100.000000    LR 0.010000    Time 0.045535    
2024-05-11 05:12:00,893 - --- validate (epoch=27)-----------
2024-05-11 05:12:00,894 - 10000 samples (100 per mini-batch)
2024-05-11 05:12:03,125 - Epoch: [27][  100/  100]    Loss 0.458453    Top1 85.580000    Top5 99.310000    
2024-05-11 05:12:03,264 - ==> Top1: 85.580    Top5: 99.310    Loss: 0.458

2024-05-11 05:12:03,264 - ==> Confusion:
[[941   9  13   3   5   0   0   3  20   6]
 [  8 950   0   0   0   0   0   3   4  35]
 [ 80   2 763  17  30  28  43  27   3   7]
 [ 46   5  46 607  49 133  39  46  13  16]
 [ 13   3  37  16 856  11  21  39   2   2]
 [ 17   1  21  58  27 817   9  42   2   6]
 [ 10   3  30  28  13  12 898   3   2   1]
 [ 18   2  12   8  14  14   2 927   2   1]
 [ 64  29   0   2   1   1   1   3 892   7]
 [ 42  35   0   1   1   0   1   2  11 907]]

2024-05-11 05:12:03,267 - ==> Best [Top1: 86.190   Top5: 99.430   Sparsity:0.00   Params: 301760 on epoch: 25]
2024-05-11 05:12:03,267 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:12:03,284 - 

2024-05-11 05:12:03,284 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:12:07,369 - Epoch: [28][  100/  500]    Overall Loss 0.304851    Objective Loss 0.304851                                        LR 0.010000    Time 0.040813    
2024-05-11 05:12:10,982 - Epoch: [28][  200/  500]    Overall Loss 0.318855    Objective Loss 0.318855                                        LR 0.010000    Time 0.038455    
2024-05-11 05:12:16,583 - Epoch: [28][  300/  500]    Overall Loss 0.323674    Objective Loss 0.323674                                        LR 0.010000    Time 0.044272    
2024-05-11 05:12:20,991 - Epoch: [28][  400/  500]    Overall Loss 0.324374    Objective Loss 0.324374                                        LR 0.010000    Time 0.044197    
2024-05-11 05:12:24,540 - Epoch: [28][  500/  500]    Overall Loss 0.324877    Objective Loss 0.324877    Top1 86.500000    Top5 100.000000    LR 0.010000    Time 0.042449    
2024-05-11 05:12:24,692 - --- validate (epoch=28)-----------
2024-05-11 05:12:24,693 - 10000 samples (100 per mini-batch)
2024-05-11 05:12:27,152 - Epoch: [28][  100/  100]    Loss 0.552652    Top1 83.330000    Top5 99.090000    
2024-05-11 05:12:27,295 - ==> Top1: 83.330    Top5: 99.090    Loss: 0.553

2024-05-11 05:12:27,296 - ==> Confusion:
[[839   5  23   7   1   0   0   2 109  14]
 [  8 880   0   1   0   1   0   0  43  67]
 [ 49   0 802  14  32  11  58  13  16   5]
 [ 30   3  82 668  35  56  50  25  37  14]
 [ 20   1  34  40 786  16  53  21  25   4]
 [ 14   2  66 124  20 702  24  30  11   7]
 [  7   2  30  13   5   1 925   7   9   1]
 [ 32   6  25  21  16  15   6 851  17  11]
 [ 18   2   2   3   0   0   3   0 970   2]
 [  8  19   3   2   0   0   2   0  56 910]]

2024-05-11 05:12:27,298 - ==> Best [Top1: 86.190   Top5: 99.430   Sparsity:0.00   Params: 301760 on epoch: 25]
2024-05-11 05:12:27,298 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:12:27,315 - 

2024-05-11 05:12:27,316 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:12:33,170 - Epoch: [29][  100/  500]    Overall Loss 0.318461    Objective Loss 0.318461                                        LR 0.010000    Time 0.058426    
2024-05-11 05:12:39,222 - Epoch: [29][  200/  500]    Overall Loss 0.318478    Objective Loss 0.318478                                        LR 0.010000    Time 0.059396    
2024-05-11 05:12:44,202 - Epoch: [29][  300/  500]    Overall Loss 0.318640    Objective Loss 0.318640                                        LR 0.010000    Time 0.056182    
2024-05-11 05:12:48,706 - Epoch: [29][  400/  500]    Overall Loss 0.316102    Objective Loss 0.316102                                        LR 0.010000    Time 0.053386    
2024-05-11 05:12:54,226 - Epoch: [29][  500/  500]    Overall Loss 0.316004    Objective Loss 0.316004    Top1 85.500000    Top5 98.500000    LR 0.010000    Time 0.053713    
2024-05-11 05:12:54,373 - --- validate (epoch=29)-----------
2024-05-11 05:12:54,373 - 10000 samples (100 per mini-batch)
2024-05-11 05:12:56,615 - Epoch: [29][  100/  100]    Loss 0.555833    Top1 82.540000    Top5 99.170000    
2024-05-11 05:12:56,770 - ==> Top1: 82.540    Top5: 99.170    Loss: 0.556

2024-05-11 05:12:56,771 - ==> Confusion:
[[907  33  17   0   2   3   0  11  20   7]
 [  5 985   0   1   0   0   0   0   2   7]
 [ 56   7 775   7  26  46  30  41   4   8]
 [ 42  18  52 388  29 330  45  68   7  21]
 [ 21   6  45  12 787  39  13  74   3   0]
 [ 11   4  16  17  15 883   8  43   0   3]
 [  9  11  28  20  11  19 884  14   3   1]
 [ 12   5   4   1   7  30   1 936   0   4]
 [ 51  51   1   2   1   2   0   2 880  10]
 [ 16 144   1   0   0   1   1   3   5 829]]

2024-05-11 05:12:56,774 - ==> Best [Top1: 86.190   Top5: 99.430   Sparsity:0.00   Params: 301760 on epoch: 25]
2024-05-11 05:12:56,774 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:12:56,793 - 

2024-05-11 05:12:56,793 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:13:00,913 - Epoch: [30][  100/  500]    Overall Loss 0.310414    Objective Loss 0.310414                                        LR 0.010000    Time 0.041158    
2024-05-11 05:13:05,013 - Epoch: [30][  200/  500]    Overall Loss 0.311784    Objective Loss 0.311784                                        LR 0.010000    Time 0.041063    
2024-05-11 05:13:10,906 - Epoch: [30][  300/  500]    Overall Loss 0.313119    Objective Loss 0.313119                                        LR 0.010000    Time 0.046955    
2024-05-11 05:13:14,551 - Epoch: [30][  400/  500]    Overall Loss 0.315544    Objective Loss 0.315544                                        LR 0.010000    Time 0.044309    
2024-05-11 05:13:18,137 - Epoch: [30][  500/  500]    Overall Loss 0.316239    Objective Loss 0.316239    Top1 89.500000    Top5 100.000000    LR 0.010000    Time 0.042613    
2024-05-11 05:13:18,291 - --- validate (epoch=30)-----------
2024-05-11 05:13:18,291 - 10000 samples (100 per mini-batch)
2024-05-11 05:13:20,788 - Epoch: [30][  100/  100]    Loss 0.508561    Top1 83.640000    Top5 99.330000    
2024-05-11 05:13:20,938 - ==> Top1: 83.640    Top5: 99.330    Loss: 0.509

2024-05-11 05:13:20,939 - ==> Confusion:
[[819   4  65  10  15   0  16   4  42  25]
 [  5 926   1   2   1   4  14   0   9  38]
 [ 21   1 831  11  31  26  72   2   3   2]
 [ 10   0  85 569  45 178  97  10   3   3]
 [  2   1  52  13 831  29  62   7   3   0]
 [  4   0  37  57  21 856  20   5   0   0]
 [  3   0  40   7   3   5 941   0   1   0]
 [  9   1  35  13  37  93  16 782   6   8]
 [ 28   8   8   3   2   2  21   0 923   5]
 [ 11  43   5   7   0   4  18   1  25 886]]

2024-05-11 05:13:20,942 - ==> Best [Top1: 86.190   Top5: 99.430   Sparsity:0.00   Params: 301760 on epoch: 25]
2024-05-11 05:13:20,942 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:13:20,959 - 

2024-05-11 05:13:20,960 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:13:27,438 - Epoch: [31][  100/  500]    Overall Loss 0.306301    Objective Loss 0.306301                                        LR 0.010000    Time 0.064749    
2024-05-11 05:13:31,287 - Epoch: [31][  200/  500]    Overall Loss 0.303253    Objective Loss 0.303253                                        LR 0.010000    Time 0.051556    
2024-05-11 05:13:34,846 - Epoch: [31][  300/  500]    Overall Loss 0.306605    Objective Loss 0.306605                                        LR 0.010000    Time 0.046223    
2024-05-11 05:13:38,682 - Epoch: [31][  400/  500]    Overall Loss 0.309930    Objective Loss 0.309930                                        LR 0.010000    Time 0.044253    
2024-05-11 05:13:44,337 - Epoch: [31][  500/  500]    Overall Loss 0.310106    Objective Loss 0.310106    Top1 90.000000    Top5 100.000000    LR 0.010000    Time 0.046667    
2024-05-11 05:13:44,586 - --- validate (epoch=31)-----------
2024-05-11 05:13:44,588 - 10000 samples (100 per mini-batch)
2024-05-11 05:13:46,840 - Epoch: [31][  100/  100]    Loss 0.455429    Top1 85.610000    Top5 99.200000    
2024-05-11 05:13:46,978 - ==> Top1: 85.610    Top5: 99.200    Loss: 0.455

2024-05-11 05:13:46,979 - ==> Confusion:
[[877   7  39   5   9   0   1   2  41  19]
 [  7 930   0   2   0   0   0   0   6  55]
 [ 31   1 846  31  24  11  28  12   8   8]
 [ 22   3  73 730  38  64  21  20   9  20]
 [ 11   3  53  35 817  18  18  41   4   0]
 [ 16   0  40 106  25 751   4  36   6  16]
 [  8   2  48  61  15   8 841   5   4   8]
 [ 18   1  28  23  20  10   0 887   1  12]
 [ 32   8   8   1   0   0   0   1 935  15]
 [ 11  16   2   3   1   0   1   0  19 947]]

2024-05-11 05:13:46,981 - ==> Best [Top1: 86.190   Top5: 99.430   Sparsity:0.00   Params: 301760 on epoch: 25]
2024-05-11 05:13:46,982 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:13:46,999 - 

2024-05-11 05:13:46,999 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:13:51,144 - Epoch: [32][  100/  500]    Overall Loss 0.290720    Objective Loss 0.290720                                        LR 0.010000    Time 0.041413    
2024-05-11 05:13:54,739 - Epoch: [32][  200/  500]    Overall Loss 0.292576    Objective Loss 0.292576                                        LR 0.010000    Time 0.038669    
2024-05-11 05:14:00,610 - Epoch: [32][  300/  500]    Overall Loss 0.294331    Objective Loss 0.294331                                        LR 0.010000    Time 0.045339    
2024-05-11 05:14:04,965 - Epoch: [32][  400/  500]    Overall Loss 0.297265    Objective Loss 0.297265                                        LR 0.010000    Time 0.044849    
2024-05-11 05:14:08,651 - Epoch: [32][  500/  500]    Overall Loss 0.298103    Objective Loss 0.298103    Top1 91.000000    Top5 99.500000    LR 0.010000    Time 0.043247    
2024-05-11 05:14:08,804 - --- validate (epoch=32)-----------
2024-05-11 05:14:08,806 - 10000 samples (100 per mini-batch)
2024-05-11 05:14:11,165 - Epoch: [32][  100/  100]    Loss 0.478581    Top1 84.890000    Top5 99.180000    
2024-05-11 05:14:11,321 - ==> Top1: 84.890    Top5: 99.180    Loss: 0.479

2024-05-11 05:14:11,321 - ==> Confusion:
[[853   3  77  17   8   0  15  11  13   3]
 [ 11 938   9   9   0   1  11   3   6  12]
 [ 22   0 850  22  33  12  45  15   0   1]
 [  8   1  50 772  30  40  79  17   2   1]
 [  4   0  27  39 844  10  53  22   1   0]
 [  4   0  42 178  28 673  37  37   0   1]
 [  2   0  23  21   5   1 946   2   0   0]
 [  5   0  19  23  25  15   6 906   0   1]
 [ 53   7  17  14   5   0  26   5 871   2]
 [ 31  63  15  15   0   1  17  12  10 836]]

2024-05-11 05:14:11,324 - ==> Best [Top1: 86.190   Top5: 99.430   Sparsity:0.00   Params: 301760 on epoch: 25]
2024-05-11 05:14:11,324 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:14:11,341 - 

2024-05-11 05:14:11,341 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:14:17,299 - Epoch: [33][  100/  500]    Overall Loss 0.293105    Objective Loss 0.293105                                        LR 0.010000    Time 0.059542    
2024-05-11 05:14:21,933 - Epoch: [33][  200/  500]    Overall Loss 0.286436    Objective Loss 0.286436                                        LR 0.010000    Time 0.052927    
2024-05-11 05:14:25,614 - Epoch: [33][  300/  500]    Overall Loss 0.290544    Objective Loss 0.290544                                        LR 0.010000    Time 0.047545    
2024-05-11 05:14:29,347 - Epoch: [33][  400/  500]    Overall Loss 0.292705    Objective Loss 0.292705                                        LR 0.010000    Time 0.044986    
2024-05-11 05:14:34,701 - Epoch: [33][  500/  500]    Overall Loss 0.295759    Objective Loss 0.295759    Top1 87.000000    Top5 99.500000    LR 0.010000    Time 0.046681    
2024-05-11 05:14:34,974 - --- validate (epoch=33)-----------
2024-05-11 05:14:34,975 - 10000 samples (100 per mini-batch)
2024-05-11 05:14:37,196 - Epoch: [33][  100/  100]    Loss 0.434543    Top1 86.280000    Top5 99.410000    
2024-05-11 05:14:37,337 - ==> Top1: 86.280    Top5: 99.410    Loss: 0.435

2024-05-11 05:14:37,338 - ==> Confusion:
[[910  10  15   1   6   0   2   3  47   6]
 [  4 962   0   0   1   0   0   0  11  22]
 [ 50   3 790  12  65  15  41  15   5   4]
 [ 28   5  39 684  72  50  75  24  16   7]
 [ 10   1  22   7 908  12  14  17   8   1]
 [ 16   2  34 127  51 717  24  24   3   2]
 [  7   4  22   8  25   1 927   4   2   0]
 [ 14   2   8  16  36  21   2 895   3   3]
 [ 25  14   2   0   1   0   4   1 952   1]
 [ 34  48   0   0   1   1   4   4  25 883]]

2024-05-11 05:14:37,341 - ==> Best [Top1: 86.280   Top5: 99.410   Sparsity:0.00   Params: 301760 on epoch: 33]
2024-05-11 05:14:37,341 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:14:37,364 - 

2024-05-11 05:14:37,364 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:14:41,768 - Epoch: [34][  100/  500]    Overall Loss 0.277241    Objective Loss 0.277241                                        LR 0.010000    Time 0.043999    
2024-05-11 05:14:45,498 - Epoch: [34][  200/  500]    Overall Loss 0.283200    Objective Loss 0.283200                                        LR 0.010000    Time 0.040633    
2024-05-11 05:14:51,342 - Epoch: [34][  300/  500]    Overall Loss 0.286693    Objective Loss 0.286693                                        LR 0.010000    Time 0.046560    
2024-05-11 05:14:55,480 - Epoch: [34][  400/  500]    Overall Loss 0.288240    Objective Loss 0.288240                                        LR 0.010000    Time 0.045249    
2024-05-11 05:14:59,137 - Epoch: [34][  500/  500]    Overall Loss 0.290127    Objective Loss 0.290127    Top1 91.000000    Top5 99.500000    LR 0.010000    Time 0.043508    
2024-05-11 05:14:59,294 - --- validate (epoch=34)-----------
2024-05-11 05:14:59,294 - 10000 samples (100 per mini-batch)
2024-05-11 05:15:01,441 - Epoch: [34][  100/  100]    Loss 0.440587    Top1 86.070000    Top5 99.510000    
2024-05-11 05:15:01,591 - ==> Top1: 86.070    Top5: 99.510    Loss: 0.441

2024-05-11 05:15:01,592 - ==> Confusion:
[[831   2  37  17  17   1   6   4  77   8]
 [  9 836   2   2   0   0   1   1  49 100]
 [ 24   0 824  38  49  15  31   8   6   5]
 [  8   0  38 756  48  90  31  12   5  12]
 [  2   0  27  34 888  16  16  15   2   0]
 [  5   0  18 114  33 807   5  16   1   1]
 [  4   0  24  49  18  15 881   4   4   1]
 [  4   1  23  32  31  15   1 885   5   3]
 [ 19   1   1   5   2   1   1   4 962   4]
 [ 10   8   4   6   1   0   1   0  33 937]]

2024-05-11 05:15:01,594 - ==> Best [Top1: 86.280   Top5: 99.410   Sparsity:0.00   Params: 301760 on epoch: 33]
2024-05-11 05:15:01,595 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:15:01,612 - 

2024-05-11 05:15:01,612 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:15:07,404 - Epoch: [35][  100/  500]    Overall Loss 0.258017    Objective Loss 0.258017                                        LR 0.010000    Time 0.057874    
2024-05-11 05:15:13,108 - Epoch: [35][  200/  500]    Overall Loss 0.271775    Objective Loss 0.271775                                        LR 0.010000    Time 0.057427    
2024-05-11 05:15:18,433 - Epoch: [35][  300/  500]    Overall Loss 0.279878    Objective Loss 0.279878                                        LR 0.010000    Time 0.055989    
2024-05-11 05:15:23,358 - Epoch: [35][  400/  500]    Overall Loss 0.284004    Objective Loss 0.284004                                        LR 0.010000    Time 0.054296    
2024-05-11 05:15:28,745 - Epoch: [35][  500/  500]    Overall Loss 0.285483    Objective Loss 0.285483    Top1 87.500000    Top5 100.000000    LR 0.010000    Time 0.054191    
2024-05-11 05:15:28,905 - --- validate (epoch=35)-----------
2024-05-11 05:15:28,906 - 10000 samples (100 per mini-batch)
2024-05-11 05:15:31,125 - Epoch: [35][  100/  100]    Loss 0.435924    Top1 86.440000    Top5 99.460000    
2024-05-11 05:15:31,263 - ==> Top1: 86.440    Top5: 99.460    Loss: 0.436

2024-05-11 05:15:31,263 - ==> Confusion:
[[860   3  49  21   7   1   4   3  40  12]
 [ 13 871   5   4   0   0   1   1  21  84]
 [ 20   0 882  15  17  25  22  12   2   5]
 [  7   1  71 739  30  95  35  10   3   9]
 [  4   0  80  38 829  14   7  26   1   1]
 [  5   0  46  93  27 797   8  21   1   2]
 [  5   1  47  38  12  10 884   2   1   0]
 [  6   0  27  20  18  18   0 905   2   4]
 [ 33   4   9   7   0   2   4   4 932   5]
 [ 15  11   7   8   0   0   1   0  13 945]]

2024-05-11 05:15:31,266 - ==> Best [Top1: 86.440   Top5: 99.460   Sparsity:0.00   Params: 301760 on epoch: 35]
2024-05-11 05:15:31,266 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:15:31,288 - 

2024-05-11 05:15:31,288 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:15:35,362 - Epoch: [36][  100/  500]    Overall Loss 0.262296    Objective Loss 0.262296                                        LR 0.010000    Time 0.040698    
2024-05-11 05:15:39,829 - Epoch: [36][  200/  500]    Overall Loss 0.272206    Objective Loss 0.272206                                        LR 0.010000    Time 0.042667    
2024-05-11 05:15:45,432 - Epoch: [36][  300/  500]    Overall Loss 0.276508    Objective Loss 0.276508                                        LR 0.010000    Time 0.047115    
2024-05-11 05:15:49,064 - Epoch: [36][  400/  500]    Overall Loss 0.279509    Objective Loss 0.279509                                        LR 0.010000    Time 0.044408    
2024-05-11 05:15:52,733 - Epoch: [36][  500/  500]    Overall Loss 0.282975    Objective Loss 0.282975    Top1 90.000000    Top5 99.500000    LR 0.010000    Time 0.042859    
2024-05-11 05:15:52,894 - --- validate (epoch=36)-----------
2024-05-11 05:15:52,894 - 10000 samples (100 per mini-batch)
2024-05-11 05:15:55,130 - Epoch: [36][  100/  100]    Loss 0.513619    Top1 84.290000    Top5 99.310000    
2024-05-11 05:15:55,355 - ==> Top1: 84.290    Top5: 99.310    Loss: 0.514

2024-05-11 05:15:55,356 - ==> Confusion:
[[946  13  18   0   7   0   0   0  15   1]
 [  9 965   0   0   1   1   0   1  13  10]
 [ 61   1 851  18  29  11  13  10   3   3]
 [ 63  10 100 627  58  57  30  33  12  10]
 [ 25   1  47   3 895   5   7  13   4   0]
 [ 30   3  57  94  38 712   9  52   1   4]
 [ 28   6  77  12  15   3 851   3   4   1]
 [ 32   2  26   7  48  11   0 873   0   1]
 [ 65  20   3   4   1   0   0   0 906   1]
 [ 72 103   2   2   2   0   0   2  14 803]]

2024-05-11 05:15:55,360 - ==> Best [Top1: 86.440   Top5: 99.460   Sparsity:0.00   Params: 301760 on epoch: 35]
2024-05-11 05:15:55,360 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:15:55,385 - 

2024-05-11 05:15:55,386 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:16:02,177 - Epoch: [37][  100/  500]    Overall Loss 0.261077    Objective Loss 0.261077                                        LR 0.010000    Time 0.067874    
2024-05-11 05:16:05,724 - Epoch: [37][  200/  500]    Overall Loss 0.268947    Objective Loss 0.268947                                        LR 0.010000    Time 0.051658    
2024-05-11 05:16:09,406 - Epoch: [37][  300/  500]    Overall Loss 0.276675    Objective Loss 0.276675                                        LR 0.010000    Time 0.046705    
2024-05-11 05:16:13,548 - Epoch: [37][  400/  500]    Overall Loss 0.276686    Objective Loss 0.276686                                        LR 0.010000    Time 0.045375    
2024-05-11 05:16:19,354 - Epoch: [37][  500/  500]    Overall Loss 0.276603    Objective Loss 0.276603    Top1 92.000000    Top5 99.500000    LR 0.010000    Time 0.047888    
2024-05-11 05:16:19,509 - --- validate (epoch=37)-----------
2024-05-11 05:16:19,509 - 10000 samples (100 per mini-batch)
2024-05-11 05:16:21,748 - Epoch: [37][  100/  100]    Loss 0.427390    Top1 86.750000    Top5 99.330000    
2024-05-11 05:16:21,891 - ==> Top1: 86.750    Top5: 99.330    Loss: 0.427

2024-05-11 05:16:21,892 - ==> Confusion:
[[901  12   5  13   5   0   0   1  42  21]
 [  6 952   0   2   0   0   0   0  10  30]
 [ 67   0 751  41  47  28  42   9   8   7]
 [ 24   6  16 780  36  66  48   4  12   8]
 [ 13   1  14  40 863  19  32  16   2   0]
 [ 13   1  17 137  22 782  14   9   2   3]
 [  9   3  15  27  13   4 923   1   2   3]
 [ 15   2   5  38  36  41   3 849   5   6]
 [ 25  10   1   3   1   1   3   1 945  10]
 [ 10  35   0   7   1   0   5   0  13 929]]

2024-05-11 05:16:21,894 - ==> Best [Top1: 86.750   Top5: 99.330   Sparsity:0.00   Params: 301760 on epoch: 37]
2024-05-11 05:16:21,895 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:16:21,917 - 

2024-05-11 05:16:21,918 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:16:26,007 - Epoch: [38][  100/  500]    Overall Loss 0.262070    Objective Loss 0.262070                                        LR 0.010000    Time 0.040856    
2024-05-11 05:16:29,852 - Epoch: [38][  200/  500]    Overall Loss 0.269926    Objective Loss 0.269926                                        LR 0.010000    Time 0.039638    
2024-05-11 05:16:35,628 - Epoch: [38][  300/  500]    Overall Loss 0.273614    Objective Loss 0.273614                                        LR 0.010000    Time 0.045647    
2024-05-11 05:16:39,266 - Epoch: [38][  400/  500]    Overall Loss 0.275526    Objective Loss 0.275526                                        LR 0.010000    Time 0.043308    
2024-05-11 05:16:42,812 - Epoch: [38][  500/  500]    Overall Loss 0.275604    Objective Loss 0.275604    Top1 89.000000    Top5 99.500000    LR 0.010000    Time 0.041721    
2024-05-11 05:16:42,976 - --- validate (epoch=38)-----------
2024-05-11 05:16:42,976 - 10000 samples (100 per mini-batch)
2024-05-11 05:16:45,365 - Epoch: [38][  100/  100]    Loss 0.495476    Top1 85.700000    Top5 99.310000    
2024-05-11 05:16:45,509 - ==> Top1: 85.700    Top5: 99.310    Loss: 0.495

2024-05-11 05:16:45,509 - ==> Confusion:
[[792  12   9   9   5   1   4   1 136  31]
 [  4 912   0   0   0   0   1   0  12  71]
 [ 51   2 707  62  42  20  70  22  10  14]
 [ 22   5  11 789  20  56  49  17  11  20]
 [  9   2  14  52 841  17  26  23   9   7]
 [ 12   1   7 138  20 766  16  28   1  11]
 [  4   1   6  32   8   3 935   3   2   6]
 [ 11   2   3  24  23  16   3 902   4  12]
 [  8   8   0   3   0   0   4   3 968   6]
 [  1  16   0   2   0   0   3   0  20 958]]

2024-05-11 05:16:45,513 - ==> Best [Top1: 86.750   Top5: 99.330   Sparsity:0.00   Params: 301760 on epoch: 37]
2024-05-11 05:16:45,513 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:16:45,531 - 

2024-05-11 05:16:45,531 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:16:51,939 - Epoch: [39][  100/  500]    Overall Loss 0.256237    Objective Loss 0.256237                                        LR 0.010000    Time 0.063902    
2024-05-11 05:16:55,838 - Epoch: [39][  200/  500]    Overall Loss 0.261727    Objective Loss 0.261727                                        LR 0.010000    Time 0.051410    
2024-05-11 05:16:59,451 - Epoch: [39][  300/  500]    Overall Loss 0.265343    Objective Loss 0.265343                                        LR 0.010000    Time 0.046308    
2024-05-11 05:17:03,350 - Epoch: [39][  400/  500]    Overall Loss 0.267762    Objective Loss 0.267762                                        LR 0.010000    Time 0.044474    
2024-05-11 05:17:08,931 - Epoch: [39][  500/  500]    Overall Loss 0.271395    Objective Loss 0.271395    Top1 91.000000    Top5 100.000000    LR 0.010000    Time 0.046735    
2024-05-11 05:17:09,201 - --- validate (epoch=39)-----------
2024-05-11 05:17:09,202 - 10000 samples (100 per mini-batch)
2024-05-11 05:17:11,428 - Epoch: [39][  100/  100]    Loss 0.434385    Top1 86.260000    Top5 99.410000    
2024-05-11 05:17:11,568 - ==> Top1: 86.260    Top5: 99.410    Loss: 0.434

2024-05-11 05:17:11,569 - ==> Confusion:
[[884   7  23   7   6   4   0  19  37  13]
 [  4 937   0   0   3   2   0   3  10  41]
 [ 30   1 828  15  34  36  12  32   5   7]
 [ 18   1  52 636  53 154  14  58   3  11]
 [  2   0  44  17 844  36   5  49   3   0]
 [  3   0  15  49  19 858   1  49   3   3]
 [  8   2  60  51  22  20 816  14   2   5]
 [  4   0   7   7  10  18   0 952   0   2]
 [ 30   6   1   6   3   2   0   5 930  17]
 [ 15  19   3   3   0   3   1   3  12 941]]

2024-05-11 05:17:11,572 - ==> Best [Top1: 86.750   Top5: 99.330   Sparsity:0.00   Params: 301760 on epoch: 37]
2024-05-11 05:17:11,572 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:17:11,589 - 

2024-05-11 05:17:11,589 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:17:15,668 - Epoch: [40][  100/  500]    Overall Loss 0.253452    Objective Loss 0.253452                                        LR 0.010000    Time 0.040755    
2024-05-11 05:17:19,307 - Epoch: [40][  200/  500]    Overall Loss 0.264369    Objective Loss 0.264369                                        LR 0.010000    Time 0.038560    
2024-05-11 05:17:25,048 - Epoch: [40][  300/  500]    Overall Loss 0.267163    Objective Loss 0.267163                                        LR 0.010000    Time 0.044831    
2024-05-11 05:17:29,313 - Epoch: [40][  400/  500]    Overall Loss 0.265592    Objective Loss 0.265592                                        LR 0.010000    Time 0.044278    
2024-05-11 05:17:32,949 - Epoch: [40][  500/  500]    Overall Loss 0.268206    Objective Loss 0.268206    Top1 89.000000    Top5 100.000000    LR 0.010000    Time 0.042691    
2024-05-11 05:17:33,097 - --- validate (epoch=40)-----------
2024-05-11 05:17:33,098 - 10000 samples (100 per mini-batch)
2024-05-11 05:17:35,341 - Epoch: [40][  100/  100]    Loss 0.457169    Top1 86.250000    Top5 99.450000    
2024-05-11 05:17:35,481 - ==> Top1: 86.250    Top5: 99.450    Loss: 0.457

2024-05-11 05:17:35,481 - ==> Confusion:
[[821   1  29  21  10   3   0   8  93  14]
 [  5 905   0   2   1   3   1   2  43  38]
 [ 25   0 790  39  54  41  21  14   9   7]
 [  8   0  29 725  36 147  28  11   9   7]
 [  4   2  18  29 880  23  10  30   4   0]
 [  3   0   4  70  21 876   1  20   4   1]
 [  5   2  32  63  23  14 855   3   1   2]
 [  4   0  14  17  26  31   1 904   2   1]
 [ 13   3   2   5   1   1   4   1 966   4]
 [  9  23   4   6   0   2   2   3  48 903]]

2024-05-11 05:17:35,484 - ==> Best [Top1: 86.750   Top5: 99.330   Sparsity:0.00   Params: 301760 on epoch: 37]
2024-05-11 05:17:35,484 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:17:35,501 - 

2024-05-11 05:17:35,502 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:17:41,665 - Epoch: [41][  100/  500]    Overall Loss 0.244523    Objective Loss 0.244523                                        LR 0.010000    Time 0.061484    
2024-05-11 05:17:46,886 - Epoch: [41][  200/  500]    Overall Loss 0.255251    Objective Loss 0.255251                                        LR 0.010000    Time 0.056833    
2024-05-11 05:17:52,638 - Epoch: [41][  300/  500]    Overall Loss 0.252474    Objective Loss 0.252474                                        LR 0.010000    Time 0.057031    
2024-05-11 05:17:57,465 - Epoch: [41][  400/  500]    Overall Loss 0.255688    Objective Loss 0.255688                                        LR 0.010000    Time 0.054820    
2024-05-11 05:18:02,863 - Epoch: [41][  500/  500]    Overall Loss 0.258925    Objective Loss 0.258925    Top1 88.500000    Top5 100.000000    LR 0.010000    Time 0.054646    
2024-05-11 05:18:03,028 - --- validate (epoch=41)-----------
2024-05-11 05:18:03,029 - 10000 samples (100 per mini-batch)
2024-05-11 05:18:05,225 - Epoch: [41][  100/  100]    Loss 0.419705    Top1 86.980000    Top5 99.540000    
2024-05-11 05:18:05,364 - ==> Top1: 86.980    Top5: 99.540    Loss: 0.420

2024-05-11 05:18:05,364 - ==> Confusion:
[[922   7  13  10   4   0   8   2  23  11]
 [  6 967   0   0   1   1   1   0   4  20]
 [ 40   1 799  39  19  23  56  15   4   4]
 [ 18   6  25 760  16 106  38  16   5  10]
 [  9   1  39  50 762  45  45  46   2   1]
 [  8   2  24  95  11 825   8  25   0   2]
 [  5   1  12  37   2   9 929   4   0   1]
 [ 11   5  13  20   5  25   1 914   0   6]
 [ 40  18   1   7   2   3   4   3 910  12]
 [ 15  55   1   3   1   2   3   1   9 910]]

2024-05-11 05:18:05,367 - ==> Best [Top1: 86.980   Top5: 99.540   Sparsity:0.00   Params: 301760 on epoch: 41]
2024-05-11 05:18:05,367 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:18:05,389 - 

2024-05-11 05:18:05,390 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:18:09,689 - Epoch: [42][  100/  500]    Overall Loss 0.247305    Objective Loss 0.247305                                        LR 0.010000    Time 0.042958    
2024-05-11 05:18:14,136 - Epoch: [42][  200/  500]    Overall Loss 0.252235    Objective Loss 0.252235                                        LR 0.010000    Time 0.043666    
2024-05-11 05:18:19,809 - Epoch: [42][  300/  500]    Overall Loss 0.252569    Objective Loss 0.252569                                        LR 0.010000    Time 0.047919    
2024-05-11 05:18:23,565 - Epoch: [42][  400/  500]    Overall Loss 0.256190    Objective Loss 0.256190                                        LR 0.010000    Time 0.045322    
2024-05-11 05:18:27,176 - Epoch: [42][  500/  500]    Overall Loss 0.258741    Objective Loss 0.258741    Top1 91.000000    Top5 100.000000    LR 0.010000    Time 0.043475    
2024-05-11 05:18:27,330 - --- validate (epoch=42)-----------
2024-05-11 05:18:27,331 - 10000 samples (100 per mini-batch)
2024-05-11 05:18:29,653 - Epoch: [42][  100/  100]    Loss 0.406299    Top1 87.090000    Top5 99.530000    
2024-05-11 05:18:29,857 - ==> Top1: 87.090    Top5: 99.530    Loss: 0.406

2024-05-11 05:18:29,858 - ==> Confusion:
[[906  11  16  10   8   1   5   2  33   8]
 [  5 958   0   0   1   0   2   1   8  25]
 [ 45   1 817  35  29  14  40  12   5   2]
 [ 20   1  41 774  27  72  39  14   4   8]
 [  9   1  35  41 860  15  20  15   4   0]
 [  9   0  24 140  25 759   8  34   0   1]
 [  7   2  33  46   8   4 897   1   1   1]
 [ 10   1  19  27  19  18   1 904   0   1]
 [ 34  14   3  10   1   1   2   1 927   7]
 [ 25  40   2   4   2   0   2   4  14 907]]

2024-05-11 05:18:29,862 - ==> Best [Top1: 87.090   Top5: 99.530   Sparsity:0.00   Params: 301760 on epoch: 42]
2024-05-11 05:18:29,862 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:18:29,900 - 

2024-05-11 05:18:29,901 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:18:36,592 - Epoch: [43][  100/  500]    Overall Loss 0.244298    Objective Loss 0.244298                                        LR 0.010000    Time 0.066879    
2024-05-11 05:18:40,352 - Epoch: [43][  200/  500]    Overall Loss 0.248363    Objective Loss 0.248363                                        LR 0.010000    Time 0.052224    
2024-05-11 05:18:43,956 - Epoch: [43][  300/  500]    Overall Loss 0.251414    Objective Loss 0.251414                                        LR 0.010000    Time 0.046820    
2024-05-11 05:18:47,917 - Epoch: [43][  400/  500]    Overall Loss 0.255462    Objective Loss 0.255462                                        LR 0.010000    Time 0.045011    
2024-05-11 05:18:53,689 - Epoch: [43][  500/  500]    Overall Loss 0.254985    Objective Loss 0.254985    Top1 91.000000    Top5 100.000000    LR 0.010000    Time 0.047541    
2024-05-11 05:18:53,912 - --- validate (epoch=43)-----------
2024-05-11 05:18:53,912 - 10000 samples (100 per mini-batch)
2024-05-11 05:18:56,133 - Epoch: [43][  100/  100]    Loss 0.514241    Top1 85.490000    Top5 99.170000    
2024-05-11 05:18:56,270 - ==> Top1: 85.490    Top5: 99.170    Loss: 0.514

2024-05-11 05:18:56,271 - ==> Confusion:
[[931  18   3   3   2   0   0   0  19  24]
 [  4 977   0   0   0   0   0   0   3  16]
 [ 96   6 783  19  25  17  25   7   6  16]
 [ 48  19  46 707  33  64  27  13   9  34]
 [ 25   4  30  22 876   9  22   6   2   4]
 [ 23  11  25 114  34 751   8  19   2  13]
 [ 20   8  35  33  12   3 869   2   2  16]
 [ 31  15  11  16  37  14   2 855   2  17]
 [ 43  31   0   1   0   0   1   0 902  22]
 [  9  84   0   0   1   0   0   0   8 898]]

2024-05-11 05:18:56,274 - ==> Best [Top1: 87.090   Top5: 99.530   Sparsity:0.00   Params: 301760 on epoch: 42]
2024-05-11 05:18:56,274 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:18:56,291 - 

2024-05-11 05:18:56,291 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:19:00,410 - Epoch: [44][  100/  500]    Overall Loss 0.243873    Objective Loss 0.243873                                        LR 0.010000    Time 0.041149    
2024-05-11 05:19:04,111 - Epoch: [44][  200/  500]    Overall Loss 0.243720    Objective Loss 0.243720                                        LR 0.010000    Time 0.039067    
2024-05-11 05:19:09,824 - Epoch: [44][  300/  500]    Overall Loss 0.245492    Objective Loss 0.245492                                        LR 0.010000    Time 0.045045    
2024-05-11 05:19:13,970 - Epoch: [44][  400/  500]    Overall Loss 0.249932    Objective Loss 0.249932                                        LR 0.010000    Time 0.044131    
2024-05-11 05:19:17,538 - Epoch: [44][  500/  500]    Overall Loss 0.251920    Objective Loss 0.251920    Top1 89.000000    Top5 100.000000    LR 0.010000    Time 0.042436    
2024-05-11 05:19:17,699 - --- validate (epoch=44)-----------
2024-05-11 05:19:17,699 - 10000 samples (100 per mini-batch)
2024-05-11 05:19:20,123 - Epoch: [44][  100/  100]    Loss 0.420684    Top1 86.800000    Top5 99.520000    
2024-05-11 05:19:20,274 - ==> Top1: 86.800    Top5: 99.520    Loss: 0.421

2024-05-11 05:19:20,275 - ==> Confusion:
[[872   9  17  22   3   0   1   2  64  10]
 [  6 944   0   2   0   0   0   0  24  24]
 [ 43   1 728  66  64  29  38  16   9   6]
 [ 14   2  13 818  37  67  34   7   2   6]
 [  4   1  13  43 889  15  20  10   4   1]
 [  7   0   5 140  31 789   6  20   0   2]
 [  6   2  21  46  15   4 901   1   3   1]
 [ 12   2   9  30  49  22   3 867   1   5]
 [ 15   6   2   8   2   1   6   0 953   7]
 [ 10  41   2   8   1   0   1   1  17 919]]

2024-05-11 05:19:20,277 - ==> Best [Top1: 87.090   Top5: 99.530   Sparsity:0.00   Params: 301760 on epoch: 42]
2024-05-11 05:19:20,278 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:19:20,297 - 

2024-05-11 05:19:20,298 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:19:26,223 - Epoch: [45][  100/  500]    Overall Loss 0.239358    Objective Loss 0.239358                                        LR 0.010000    Time 0.059158    
2024-05-11 05:19:30,898 - Epoch: [45][  200/  500]    Overall Loss 0.244906    Objective Loss 0.244906                                        LR 0.010000    Time 0.052908    
2024-05-11 05:19:34,558 - Epoch: [45][  300/  500]    Overall Loss 0.246052    Objective Loss 0.246052                                        LR 0.010000    Time 0.047461    
2024-05-11 05:19:38,191 - Epoch: [45][  400/  500]    Overall Loss 0.244441    Objective Loss 0.244441                                        LR 0.010000    Time 0.044674    
2024-05-11 05:19:43,107 - Epoch: [45][  500/  500]    Overall Loss 0.247576    Objective Loss 0.247576    Top1 85.500000    Top5 99.500000    LR 0.010000    Time 0.045565    
2024-05-11 05:19:43,344 - --- validate (epoch=45)-----------
2024-05-11 05:19:43,345 - 10000 samples (100 per mini-batch)
2024-05-11 05:19:45,557 - Epoch: [45][  100/  100]    Loss 0.471945    Top1 85.730000    Top5 99.420000    
2024-05-11 05:19:45,705 - ==> Top1: 85.730    Top5: 99.420    Loss: 0.472

2024-05-11 05:19:45,706 - ==> Confusion:
[[891  17  16   2   8   2   2   1  31  30]
 [  4 971   0   0   0   1   0   0   4  20]
 [ 59   4 802  22  37  24  16  14  11  11]
 [ 26  13  72 671  30 113  31  10  14  20]
 [ 13   3  33  23 866  21  11  24   5   1]
 [ 13   1  35  78  19 819   9  17   3   6]
 [ 16   7  48  31  11   8 862   2   9   6]
 [ 20   7  21  15  23  39   1 857   3  14]
 [ 32  26   1   3   1   0   0   0 915  22]
 [ 10  62   1   0   0   1   0   0   7 919]]

2024-05-11 05:19:45,709 - ==> Best [Top1: 87.090   Top5: 99.530   Sparsity:0.00   Params: 301760 on epoch: 42]
2024-05-11 05:19:45,709 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:19:45,727 - 

2024-05-11 05:19:45,727 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:19:49,758 - Epoch: [46][  100/  500]    Overall Loss 0.242874    Objective Loss 0.242874                                        LR 0.010000    Time 0.040271    
2024-05-11 05:19:53,258 - Epoch: [46][  200/  500]    Overall Loss 0.239265    Objective Loss 0.239265                                        LR 0.010000    Time 0.037621    
2024-05-11 05:19:58,646 - Epoch: [46][  300/  500]    Overall Loss 0.244356    Objective Loss 0.244356                                        LR 0.010000    Time 0.043034    
2024-05-11 05:20:03,224 - Epoch: [46][  400/  500]    Overall Loss 0.247577    Objective Loss 0.247577                                        LR 0.010000    Time 0.043693    
2024-05-11 05:20:06,805 - Epoch: [46][  500/  500]    Overall Loss 0.248468    Objective Loss 0.248468    Top1 93.000000    Top5 100.000000    LR 0.010000    Time 0.042113    
2024-05-11 05:20:06,955 - --- validate (epoch=46)-----------
2024-05-11 05:20:06,955 - 10000 samples (100 per mini-batch)
2024-05-11 05:20:09,338 - Epoch: [46][  100/  100]    Loss 0.475113    Top1 85.550000    Top5 99.420000    
2024-05-11 05:20:09,480 - ==> Top1: 85.550    Top5: 99.420    Loss: 0.475

2024-05-11 05:20:09,481 - ==> Confusion:
[[802  16  35   5  10   8  14   8  76  26]
 [  3 939   1   0   1   1   1   1   9  44]
 [ 21   2 783  15  40  43  69  13   6   8]
 [  7   2  37 527  28 234 110  29  11  15]
 [  5   2  20  20 841  38  40  29   5   0]
 [  5   0  13  25  20 891  14  26   2   4]
 [  4   2   5   7   4  15 959   3   1   0]
 [  5   3   5   4  17  38   6 915   1   6]
 [ 13   8   2   1   1   4   5   1 952  13]
 [  3  30   0   1   0   3   5   0  12 946]]

2024-05-11 05:20:09,483 - ==> Best [Top1: 87.090   Top5: 99.530   Sparsity:0.00   Params: 301760 on epoch: 42]
2024-05-11 05:20:09,483 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:20:09,501 - 

2024-05-11 05:20:09,501 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:20:14,932 - Epoch: [47][  100/  500]    Overall Loss 0.216881    Objective Loss 0.216881                                        LR 0.010000    Time 0.054214    
2024-05-11 05:20:19,613 - Epoch: [47][  200/  500]    Overall Loss 0.227425    Objective Loss 0.227425                                        LR 0.010000    Time 0.050498    
2024-05-11 05:20:24,416 - Epoch: [47][  300/  500]    Overall Loss 0.233652    Objective Loss 0.233652                                        LR 0.010000    Time 0.049668    
2024-05-11 05:20:30,700 - Epoch: [47][  400/  500]    Overall Loss 0.235243    Objective Loss 0.235243                                        LR 0.010000    Time 0.052922    
2024-05-11 05:20:36,482 - Epoch: [47][  500/  500]    Overall Loss 0.237795    Objective Loss 0.237795    Top1 91.000000    Top5 100.000000    LR 0.010000    Time 0.053897    
2024-05-11 05:20:36,635 - --- validate (epoch=47)-----------
2024-05-11 05:20:36,637 - 10000 samples (100 per mini-batch)
2024-05-11 05:20:38,819 - Epoch: [47][  100/  100]    Loss 0.527986    Top1 84.460000    Top5 99.310000    
2024-05-11 05:20:38,957 - ==> Top1: 84.460    Top5: 99.310    Loss: 0.528

2024-05-11 05:20:38,958 - ==> Confusion:
[[722  11  53   9  32   9   8  24 121  11]
 [  4 950   2   1   0   2   0   6  20  15]
 [ 13   0 802  17  65  26  22  50   3   2]
 [  6   0  39 624  72 172  15  68   2   2]
 [  1   1  13  10 912  22   4  36   1   0]
 [  1   0  11  45  31 849   2  60   1   0]
 [  3   3  30  51  49  25 808  27   3   1]
 [  3   0   4   6  32  12   0 943   0   0]
 [ 13   7   3   6   4   4   1   6 953   3]
 [  8  53   4   3   1   3   0  15  30 883]]

2024-05-11 05:20:38,961 - ==> Best [Top1: 87.090   Top5: 99.530   Sparsity:0.00   Params: 301760 on epoch: 42]
2024-05-11 05:20:38,961 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:20:38,978 - 

2024-05-11 05:20:38,979 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:20:43,315 - Epoch: [48][  100/  500]    Overall Loss 0.224979    Objective Loss 0.224979                                        LR 0.010000    Time 0.043325    
2024-05-11 05:20:47,269 - Epoch: [48][  200/  500]    Overall Loss 0.234303    Objective Loss 0.234303                                        LR 0.010000    Time 0.041423    
2024-05-11 05:20:53,024 - Epoch: [48][  300/  500]    Overall Loss 0.237041    Objective Loss 0.237041                                        LR 0.010000    Time 0.046767    
2024-05-11 05:20:56,643 - Epoch: [48][  400/  500]    Overall Loss 0.237569    Objective Loss 0.237569                                        LR 0.010000    Time 0.044117    
2024-05-11 05:21:00,192 - Epoch: [48][  500/  500]    Overall Loss 0.240218    Objective Loss 0.240218    Top1 93.000000    Top5 99.500000    LR 0.010000    Time 0.042385    
2024-05-11 05:21:00,348 - --- validate (epoch=48)-----------
2024-05-11 05:21:00,348 - 10000 samples (100 per mini-batch)
2024-05-11 05:21:02,553 - Epoch: [48][  100/  100]    Loss 0.424684    Top1 86.580000    Top5 99.510000    
2024-05-11 05:21:02,690 - ==> Top1: 86.580    Top5: 99.510    Loss: 0.425

2024-05-11 05:21:02,690 - ==> Confusion:
[[865   2  52   8  16   5   9   5  32   6]
 [ 13 937   2   2   2   3   0   1  15  25]
 [ 16   0 842  32  45  28  22   7   4   4]
 [ 11   0  69 729  35 127  20   6   1   2]
 [  5   0  31  42 866  28   9  17   2   0]
 [  4   1  26  97  22 834   2  12   0   2]
 [  1   0  38  58  23  23 853   2   1   1]
 [  6   1  22  30  27  25   0 887   0   2]
 [ 34   7   5   9   2   5   4   3 925   6]
 [ 17  35   4   6   0   4   2   0  12 920]]

2024-05-11 05:21:02,693 - ==> Best [Top1: 87.090   Top5: 99.530   Sparsity:0.00   Params: 301760 on epoch: 42]
2024-05-11 05:21:02,693 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:21:02,711 - 

2024-05-11 05:21:02,712 - Training epoch: 50000 samples (100 per mini-batch)
2024-05-11 05:21:09,040 - Epoch: [49][  100/  500]    Overall Loss 0.227587    Objective Loss 0.227587                                        LR 0.010000    Time 0.063122    
2024-05-11 05:21:13,370 - Epoch: [49][  200/  500]    Overall Loss 0.227993    Objective Loss 0.227993                                        LR 0.010000    Time 0.053159    
2024-05-11 05:21:16,974 - Epoch: [49][  300/  500]    Overall Loss 0.228759    Objective Loss 0.228759                                        LR 0.010000    Time 0.047412    
2024-05-11 05:21:20,615 - Epoch: [49][  400/  500]    Overall Loss 0.231047    Objective Loss 0.231047                                        LR 0.010000    Time 0.044655    
2024-05-11 05:21:26,048 - Epoch: [49][  500/  500]    Overall Loss 0.230327    Objective Loss 0.230327    Top1 93.000000    Top5 100.000000    LR 0.010000    Time 0.046584    
2024-05-11 05:21:26,300 - --- validate (epoch=49)-----------
2024-05-11 05:21:26,300 - 10000 samples (100 per mini-batch)
2024-05-11 05:21:28,543 - Epoch: [49][  100/  100]    Loss 0.431733    Top1 86.930000    Top5 99.470000    
2024-05-11 05:21:28,680 - ==> Top1: 86.930    Top5: 99.470    Loss: 0.432

2024-05-11 05:21:28,681 - ==> Confusion:
[[868   9  57  15   5   0   2   1  31  12]
 [  7 949   0   1   0   2   0   0  15  26]
 [ 14   0 868  30  23  18  30   7   5   5]
 [ 16   3  45 735  26 118  27   8  13   9]
 [ 13   1  40  36 847   9  29  21   3   1]
 [ 10   2  25  87  23 827   8  13   2   3]
 [  4   2  28  41   7   6 906   2   2   2]
 [ 15   2  32  30  27  36   2 838   8  10]
 [ 31   6   4   5   0   0   3   0 943   8]
 [ 13  45   4   6   0   1   1   0  18 912]]

2024-05-11 05:21:28,684 - ==> Best [Top1: 87.090   Top5: 99.530   Sparsity:0.00   Params: 301760 on epoch: 42]
2024-05-11 05:21:28,684 - Saving checkpoint to: logs/2024.05.11-050006/checkpoint.pth.tar
2024-05-11 05:21:28,702 - --- test ---------------------
2024-05-11 05:21:28,703 - 10000 samples (100 per mini-batch)
2024-05-11 05:21:30,862 - Test: [  100/  100]    Loss 0.431733    Top1 86.930000    Top5 99.470000    
2024-05-11 05:21:31,001 - ==> Top1: 86.930    Top5: 99.470    Loss: 0.432

2024-05-11 05:21:31,002 - ==> Confusion:
[[868   9  57  15   5   0   2   1  31  12]
 [  7 949   0   1   0   2   0   0  15  26]
 [ 14   0 868  30  23  18  30   7   5   5]
 [ 16   3  45 735  26 118  27   8  13   9]
 [ 13   1  40  36 847   9  29  21   3   1]
 [ 10   2  25  87  23 827   8  13   2   3]
 [  4   2  28  41   7   6 906   2   2   2]
 [ 15   2  32  30  27  36   2 838   8  10]
 [ 31   6   4   5   0   0   3   0 943   8]
 [ 13  45   4   6   0   1   1   0  18 912]]

2024-05-11 05:21:31,013 - 
2024-05-11 05:21:31,013 - Log file for this run: /content/ai8x-training/logs/2024.05.11-050006/2024.05.11-050006.log
